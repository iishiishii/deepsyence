{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {InferenceSession, Tensor, env} from 'onnxruntime-web';\n",
    "const ndarray = require('ndarray')\n",
    "const ops = require('ndarray-ops')\n",
    "const fs = require('fs')\n",
    "import Jimp from \"jimp\";\n",
    "import { Niivue, NVImage } from \"@niivue/niivue\";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVImage {\n",
      "  DT_NONE: 0,\n",
      "  DT_UNKNOWN: 0,\n",
      "  DT_BINARY: 1,\n",
      "  DT_UNSIGNED_CHAR: 2,\n",
      "  DT_SIGNED_SHORT: 4,\n",
      "  DT_SIGNED_INT: 8,\n",
      "  DT_FLOAT: 16,\n",
      "  DT_COMPLEX: 32,\n",
      "  DT_DOUBLE: 64,\n",
      "  DT_RGB: 128,\n",
      "  DT_ALL: 255,\n",
      "  DT_INT8: 256,\n",
      "  DT_UINT16: 512,\n",
      "  DT_UINT32: 768,\n",
      "  DT_INT64: 1024,\n",
      "  DT_UINT64: 1280,\n",
      "  DT_FLOAT128: 1536,\n",
      "  DT_COMPLEX128: 1792,\n",
      "  DT_COMPLEX256: 2048,\n",
      "  DT_RGBA32: 2304,\n",
      "  name: 'mni152.nii.gz',\n",
      "  id: 'f40c00ec-7ede-44b5-8b4d-2bdaf8bd6619',\n",
      "  _colormap: 'gray',\n",
      "  _opacity: 1,\n",
      "  percentileFrac: 0.02,\n",
      "  ignoreZeroVoxels: false,\n",
      "  trustCalMinMax: true,\n",
      "  colormapNegative: '',\n",
      "  colormapLabel: [],\n",
      "  frame4D: 0,\n",
      "  cal_minNeg: NaN,\n",
      "  cal_maxNeg: NaN,\n",
      "  colorbarVisible: true,\n",
      "  visible: true,\n",
      "  modulationImage: null,\n",
      "  modulateAlpha: 0,\n",
      "  series: [],\n",
      "  onColormapChange: [Function (anonymous)],\n",
      "  onOpacityChange: [Function (anonymous)],\n",
      "  hdr: si {\n",
      "    littleEndian: true,\n",
      "    dim_info: 0,\n",
      "    dims: [\n",
      "      3, 207, 256, 215,\n",
      "      1,   1,   1,   1\n",
      "    ],\n",
      "    intent_p1: 0,\n",
      "    intent_p2: 0,\n",
      "    intent_p3: 0,\n",
      "    intent_code: 0,\n",
      "    datatypeCode: 2,\n",
      "    numBitsPerVoxel: 8,\n",
      "    slice_start: 0,\n",
      "    slice_end: 0,\n",
      "    slice_code: 0,\n",
      "    pixDims: [\n",
      "      1,\n",
      "      0.737463116645813,\n",
      "      0.737463116645813,\n",
      "      0.737463116645813,\n",
      "      0,\n",
      "      0,\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    vox_offset: 352,\n",
      "    scl_slope: 0.3629564046859741,\n",
      "    scl_inter: 0,\n",
      "    xyzt_units: 10,\n",
      "    cal_max: 80,\n",
      "    cal_min: 40,\n",
      "    slice_duration: 0,\n",
      "    toffset: 0,\n",
      "    description: 'www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009',\n",
      "    aux_file: '',\n",
      "    intent_name: '',\n",
      "    qform_code: 2,\n",
      "    sform_code: 2,\n",
      "    quatern_a: 1,\n",
      "    quatern_b: 0,\n",
      "    quatern_c: 0,\n",
      "    quatern_d: 0,\n",
      "    qoffset_x: 0,\n",
      "    qoffset_y: 0,\n",
      "    qoffset_z: 0,\n",
      "    affine: [ [Array], [Array], [Array], [Array] ],\n",
      "    qfac: 1,\n",
      "    quatern_R: undefined,\n",
      "    magic: 'n+1',\n",
      "    isHDR: false,\n",
      "    extensionFlag: [ 0, 0, 0, 0 ],\n",
      "    extensionSize: 0,\n",
      "    extensionCode: 0,\n",
      "    extensions: [],\n",
      "    getDatatypeCodeString: [Function (anonymous)],\n",
      "    getTransformCodeString: [Function (anonymous)],\n",
      "    getUnitsCodeString: [Function (anonymous)],\n",
      "    nifti_mat33_mul: [Function (anonymous)],\n",
      "    nifti_mat33_determ: [Function (anonymous)]\n",
      "  },\n",
      "  imageType: 1,\n",
      "  nFrame4D: 1,\n",
      "  nVox3D: 11393280,\n",
      "  nTotalFrame4D: 1,\n",
      "  img: Uint8Array(11393280) [\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0,\n",
      "    ... 11393180 more items\n",
      "  ],\n",
      "  mm000: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    -111.13126373291016,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm100: Float32Array(3) [\n",
      "    76.52359771728516,\n",
      "    -111.13126373291016,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm010: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    77.65929412841797,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm001: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    -111.13126373291016,\n",
      "    86.42330169677734\n",
      "  ],\n",
      "  dimsRAS: [ 3, 207, 256, 215 ],\n",
      "  pixDimsRAS: [ 1, 0.737463116645813, 0.737463116645813, 0.737463116645813 ],\n",
      "  permRAS: [ 1, 2, 3 ],\n",
      "  toRAS: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  matRAS: Float32Array(16) [\n",
      "    0.737463116645813,                   0,\n",
      "                    0,  -75.76253509521484,\n",
      "                    0,   0.737463116645813,\n",
      "                    0, -110.76253509521484,\n",
      "                    0,                   0,\n",
      "    0.737463116645813,  -71.76253509521484,\n",
      "                    0,                   0,\n",
      "                    0,                   1\n",
      "  ],\n",
      "  oblique_angle: 0,\n",
      "  obliqueRAS: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  maxShearDeg: 0,\n",
      "  frac2mm: Float32Array(16) [\n",
      "     152.6548614501953,                   0,\n",
      "                     0,                   0,\n",
      "                     0,  188.79055786132812,\n",
      "                     0,                   0,\n",
      "                     0,                   0,\n",
      "     158.5545654296875,                   0,\n",
      "    -76.13126373291016, -111.13126373291016,\n",
      "    -72.13126373291016,                   1\n",
      "  ],\n",
      "  frac2mmOrtho: Float32Array(16) [\n",
      "     152.6548614501953,                   0,\n",
      "                     0,                   0,\n",
      "                     0,  188.79055786132812,\n",
      "                     0,                   0,\n",
      "                     0,                   0,\n",
      "     158.5545654296875,                   0,\n",
      "    -76.13127136230469, -111.13126373291016,\n",
      "    -72.13126373291016,                   1\n",
      "  ],\n",
      "  extentsMinOrtho: [ -76.13127136230469, -111.13126373291016, -72.13126373291016 ],\n",
      "  extentsMaxOrtho: [ 76.52359008789062, 77.65929412841797, 86.42330169677734 ],\n",
      "  mm2ortho: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  cal_min: 40,\n",
      "  cal_max: 80,\n",
      "  robust_min: 40,\n",
      "  robust_max: 80,\n",
      "  global_min: 40,\n",
      "  global_max: 80,\n",
      "  url: 'https://niivue.github.io/niivue-demo-images/mni152.nii.gz'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// in kernel, The configuration runs using node, and not in the browser,\n",
    "// which is why window is not defined\n",
    "// we need to define it to make the code work\n",
    "\n",
    "// global.window = { navigator: { userAgent: 'node.js' } };\n",
    "// typeof(window) === 'undefined'\n",
    "const volume = await NVImage.loadFromUrl({url:\"https://niivue.github.io/niivue-demo-images/mni152.nii.gz\"})\n",
    "console.log(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function normalizeArray(\n",
    "    array: Float32Array,\n",
    "    max: number\n",
    "  ): Float32Array {\n",
    "    let normalizedArray = new Float32Array(array.length);\n",
    "    for (let i = 0; i < array.length; i++) {\n",
    "      normalizedArray[i] = array[i] / max;\n",
    "    }\n",
    "    return normalizedArray;\n",
    "  }\n",
    "  \n",
    "  function stackSliceToRGB(\n",
    "    buffer: Float32Array | Uint8Array,\n",
    "  ): Float32Array {\n",
    "    let bufferLength = buffer.length,\n",
    "      result = new Float32Array(bufferLength * 3);\n",
    "  \n",
    "    for (let i = 0; i < bufferLength; i++) {\n",
    "      result[3 * i] = buffer[i];\n",
    "      result[3 * i + 1] = buffer[i];\n",
    "      result[3 * i + 2] = buffer[i];\n",
    "    }\n",
    "    return result;\n",
    "  }\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "const preprocessVolume = (image) => {\n",
    "    try {\n",
    "      const imageRAS = image.img2RAS();\n",
    "      console.log(\"image.calMax, image.calMin \", image.global_max, image.global_min);\n",
    "\n",
    "      const normalizedArray = normalizeArray(imageRAS, image.global_max);\n",
    "      console.log(\"normalizedArray \", normalizedArray);\n",
    "      return normalizedArray;\n",
    "    } catch (e) {\n",
    "      console.log(`failed to preprocess volume: ${e}. `);\n",
    "      throw Error(`failed to preprocess volume: ${e}. `);\n",
    "    }\n",
    "  }\n",
    "\n",
    "  const preprocess = async (slice2D: Float32Array, sliceId: number, width: number, height: number): Promise<Float32Array> => {\n",
    "    try {\n",
    "      console.log(\"imageArray \", slice2D);\n",
    "      let image3Channels: Float32Array;\n",
    "      const sliceArray = slice2D.slice(\n",
    "        width * height * sliceId,\n",
    "        width * height * (sliceId + 1),\n",
    "      );\n",
    "      console.log(\"sliceArray \", sliceArray.reduce((a, b) => a + b, 0));\n",
    "  \n",
    "      image3Channels = stackSliceToRGB(sliceArray);\n",
    "      console.log(\"image3Channels \", image3Channels, image3Channels.reduce((a, b) => a + b, 0));\n",
    "      return image3Channels;\n",
    "    } catch (e) {\n",
    "      console.log(`failed to inference ONNX model: ${e}. `);\n",
    "      throw Error(`failed to inference ONNX model: ${e}. `);\n",
    "    }\n",
    "  };\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a 3D array of size (2, 9, 5)**\n",
    "```python\n",
    "array_3d = np.array([\n",
    "    [\n",
    "        [1, 2, 3, 4, 5],\n",
    "        [6, 7, 8, 9, 10],\n",
    "        [41, 42, 43, 44, 45]\n",
    "    ],\n",
    "    [\n",
    "        [46, 47, 48, 49, 50],\n",
    "        [81, 82, 83, 84, 85],\n",
    "        [86, 87, 88, 89, 90]\n",
    "    ]\n",
    "])\n",
    "```\n",
    "\n",
    "**Get flatten array from index [:,:,1]**\n",
    "```python\n",
    "array_3d[:,:,1].flatten() \n",
    "```\n",
    "\n",
    "[ 2  7 42 47 82 87]\n",
    "\n",
    "=**Get flatten array from index [:,1,:]**\n",
    "```python\n",
    "array_3d[:,1,:].flatten()\n",
    "```\n",
    "\n",
    "[ 6  7  8  9 10 81 82 83 84 85]\n",
    "\n",
    "**Get flatten array from index [1,:,:]**\n",
    "```python\n",
    "array_3d[1,:,:].flatten()\n",
    "```\n",
    "\n",
    "[46 47 48 49 50 81 82 83 84 85 86 87 88 89 90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "// function plotArray(array, dims) {\n",
    "//     // 1. convert array to Uint8 or Float32\n",
    "//     let arrayToPlot = new Uint8Array(array);\n",
    "//     // 2. save to png\n",
    "//     imagedataToImage(arrayToPlot, dims[0], dims[1]);\n",
    "// }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nvVolumetoSlice(volume, dims, fov, index): any {\n",
    "    let sliceArray;\n",
    "    switch (fov) {\n",
    "        // sagittal dimsRAS[1], coronal dimsRAS[2], axial dimsRAS[3]\n",
    "        \n",
    "        // 1. if axial, slice the array from volume\n",
    "        case \"axial\":\n",
    "            sliceArray = volume.slice(\n",
    "                dims[0] * dims[1] * index,\n",
    "                dims[0] * dims[1] * (index + 1),\n",
    "            );\n",
    "            console.log(\"axial sliceArray\",dims[1], dims[2], index, sliceArray.length);\n",
    "        // 2. if coronal, \n",
    "        case \"coronal\":\n",
    "        // 3. if sagittal,\n",
    "        case \"sagittal\":\n",
    "    }\n",
    "    return sliceArray;\n",
    "    \n",
    "}\n",
    "\n",
    "function nvSliceToTensor(nvSlice, dims): any {\n",
    "    console.log(\"nvSlice\", nvSlice.length);\n",
    "    // 1. preprocess\n",
    "    let image3Channels = stackSliceToRGB(nvSlice);\n",
    "    // 2. convert to float32\n",
    "    console.log(\"image3Channels\", image3Channels.length);\n",
    "    // 3. tensor\n",
    "    const inputTensor = new Tensor(\"float32\", image3Channels, dims);\n",
    "    return inputTensor;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image.calMax, image.calMin  80 40\n",
      "normalizedArray  Float32Array(11393280) [\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0,\n",
      "  ... 11393180 more items\n",
      "]\n",
      "axial sliceArray 256 215 90 52992\n",
      "nvSlice 52992\n",
      "image3Channels 158976\n"
     ]
    }
   ],
   "source": [
    "const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
    "let nvVolume = preprocessVolume(volume);\n",
    "let nvSlice = nvVolumetoSlice(nvVolume, dims, \"axial\", 90);\n",
    "let inputTensor = nvSliceToTensor(nvSlice, [1, 3, dims[0], dims[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undefined 207 256\n",
      "256 207 Uint8Array(635904) [\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0,\n",
      "  ... 635804 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "console.log(inputTensor.ImgData, dims[0], dims[1])\n",
    "console.log(dst.cols, dst.rows, dst.data);\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mat {}\n"
     ]
    }
   ],
   "source": [
    "import { cv } from 'opencv-wasm'\n",
    "\n",
    "// await cv.loadOpenCV();\n",
    "let dst = cv.matFromArray(dims[0], dims[1], cv.CV_32FC3, inputTensor.data);\n",
    "console.log(dst);\n",
    "// new Jimp({\n",
    "//     width: dst.cols,\n",
    "//     height: dst.rows,\n",
    "//     data: Buffer.from(dst.data)\n",
    "// }).write('/home/thuy/repo/deepsyence/dilation.png');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputTensor 158976 [ 1, 3, 207, 256 ]\n"
     ]
    }
   ],
   "source": [
    "console.log(\"inputTensor\", inputTensor.data.length, inputTensor.dims);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "global.self = global;\n",
    "env.wasm.numThreads = 1;\n",
    "\n",
    "const encoderSession = await InferenceSession.create('/home/thuy/repo/deepsyence/public/model/efficient_sam_vitt_encoder.onnx');\n",
    "const decoderSession = await InferenceSession.create('/home/thuy/repo/deepsyence/public/model/efficient_sam_vitt_decoder.onnx');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "async function runModel(model, preprocessedData): Promise<[Tensor, number]> {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "      const feeds: Record<string, Tensor> = {};\n",
    "      feeds[model.inputNames[0]] = preprocessedData;\n",
    "      const outputData = await model.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[model.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "const [res, time] =  await runModel(encoderSession, inputTensor);\n",
    "var output = res.data;\n",
    "var inferenceTime = time;\n",
    "// var results = softmax(Array.prototype.slice.call(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1831.3217101244136 6015\n"
     ]
    }
   ],
   "source": [
    "console.log((output as Float32Array).reduce((a,b) => a + b, 0), inferenceTime);"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10bf6accb374a6da2204700f697d150b0507c8791e988710f45c7e1f2c02832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
