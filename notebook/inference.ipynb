{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Creating a 3D array of size (2, 9, 5)**\n",
    "```python\n",
    "array_3d = np.array([\n",
    "    [\n",
    "        [1, 2, 3, 4, 5],\n",
    "        [6, 7, 8, 9, 10],\n",
    "        [41, 42, 43, 44, 45]\n",
    "    ],\n",
    "    [\n",
    "        [46, 47, 48, 49, 50],\n",
    "        [81, 82, 83, 84, 85],\n",
    "        [86, 87, 88, 89, 90]\n",
    "    ]\n",
    "])\n",
    "```\n",
    "\n",
    "**Get flatten array from index [:,:,1]**\n",
    "```python\n",
    "array_3d[:,:,1].flatten() \n",
    "```\n",
    "\n",
    "[ 2  7 42 47 82 87]\n",
    "\n",
    "=**Get flatten array from index [:,1,:]**\n",
    "```python\n",
    "array_3d[:,1,:].flatten()\n",
    "```\n",
    "\n",
    "[ 6  7  8  9 10 81 82 83 84 85]\n",
    "\n",
    "**Get flatten array from index [1,:,:]**\n",
    "```python\n",
    "array_3d[1,:,:].flatten()\n",
    "```\n",
    "\n",
    "[46 47 48 49 50 81 82 83 84 85 86 87 88 89 90]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {InferenceSession, Tensor, env} from 'onnxruntime-web';\n",
    "const ndarray = require('ndarray')\n",
    "const ops = require('ndarray-ops')\n",
    "const fs = require('fs')\n",
    "import Jimp from \"jimp\";\n",
    "import { Niivue, NVImage } from \"@niivue/niivue\";\n",
    "import { cv } from \"opencv-wasm\";\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NVImage {\n",
      "  DT_NONE: 0,\n",
      "  DT_UNKNOWN: 0,\n",
      "  DT_BINARY: 1,\n",
      "  DT_UNSIGNED_CHAR: 2,\n",
      "  DT_SIGNED_SHORT: 4,\n",
      "  DT_SIGNED_INT: 8,\n",
      "  DT_FLOAT: 16,\n",
      "  DT_COMPLEX: 32,\n",
      "  DT_DOUBLE: 64,\n",
      "  DT_RGB: 128,\n",
      "  DT_ALL: 255,\n",
      "  DT_INT8: 256,\n",
      "  DT_UINT16: 512,\n",
      "  DT_UINT32: 768,\n",
      "  DT_INT64: 1024,\n",
      "  DT_UINT64: 1280,\n",
      "  DT_FLOAT128: 1536,\n",
      "  DT_COMPLEX128: 1792,\n",
      "  DT_COMPLEX256: 2048,\n",
      "  DT_RGBA32: 2304,\n",
      "  name: 'mni152.nii.gz',\n",
      "  id: '592b5bdd-4a35-493e-95f7-c24f12fd5413',\n",
      "  _colormap: 'gray',\n",
      "  _opacity: 1,\n",
      "  percentileFrac: 0.02,\n",
      "  ignoreZeroVoxels: false,\n",
      "  trustCalMinMax: true,\n",
      "  colormapNegative: '',\n",
      "  colormapLabel: [],\n",
      "  frame4D: 0,\n",
      "  cal_minNeg: NaN,\n",
      "  cal_maxNeg: NaN,\n",
      "  colorbarVisible: true,\n",
      "  visible: true,\n",
      "  modulationImage: null,\n",
      "  modulateAlpha: 0,\n",
      "  series: [],\n",
      "  onColormapChange: [Function (anonymous)],\n",
      "  onOpacityChange: [Function (anonymous)],\n",
      "  hdr: si {\n",
      "    littleEndian: true,\n",
      "    dim_info: 0,\n",
      "    dims: [\n",
      "      3, 207, 256, 215,\n",
      "      1,   1,   1,   1\n",
      "    ],\n",
      "    intent_p1: 0,\n",
      "    intent_p2: 0,\n",
      "    intent_p3: 0,\n",
      "    intent_code: 0,\n",
      "    datatypeCode: 2,\n",
      "    numBitsPerVoxel: 8,\n",
      "    slice_start: 0,\n",
      "    slice_end: 0,\n",
      "    slice_code: 0,\n",
      "    pixDims: [\n",
      "      1,\n",
      "      0.737463116645813,\n",
      "      0.737463116645813,\n",
      "      0.737463116645813,\n",
      "      0,\n",
      "      0,\n",
      "      0,\n",
      "      0\n",
      "    ],\n",
      "    vox_offset: 352,\n",
      "    scl_slope: 0.3629564046859741,\n",
      "    scl_inter: 0,\n",
      "    xyzt_units: 10,\n",
      "    cal_max: 80,\n",
      "    cal_min: 40,\n",
      "    slice_duration: 0,\n",
      "    toffset: 0,\n",
      "    description: 'www.bic.mni.mcgill.ca/ServicesAtlases/ICBM152NLin2009',\n",
      "    aux_file: '',\n",
      "    intent_name: '',\n",
      "    qform_code: 2,\n",
      "    sform_code: 2,\n",
      "    quatern_a: 1,\n",
      "    quatern_b: 0,\n",
      "    quatern_c: 0,\n",
      "    quatern_d: 0,\n",
      "    qoffset_x: 0,\n",
      "    qoffset_y: 0,\n",
      "    qoffset_z: 0,\n",
      "    affine: [ [Array], [Array], [Array], [Array] ],\n",
      "    qfac: 1,\n",
      "    quatern_R: undefined,\n",
      "    magic: 'n+1',\n",
      "    isHDR: false,\n",
      "    extensionFlag: [ 0, 0, 0, 0 ],\n",
      "    extensionSize: 0,\n",
      "    extensionCode: 0,\n",
      "    extensions: [],\n",
      "    getDatatypeCodeString: [Function (anonymous)],\n",
      "    getTransformCodeString: [Function (anonymous)],\n",
      "    getUnitsCodeString: [Function (anonymous)],\n",
      "    nifti_mat33_mul: [Function (anonymous)],\n",
      "    nifti_mat33_determ: [Function (anonymous)]\n",
      "  },\n",
      "  imageType: 1,\n",
      "  nFrame4D: 1,\n",
      "  nVox3D: 11393280,\n",
      "  nTotalFrame4D: 1,\n",
      "  img: Uint8Array(11393280) [\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "    0, 0, 0, 0,\n",
      "    ... 11393180 more items\n",
      "  ],\n",
      "  mm000: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    -111.13126373291016,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm100: Float32Array(3) [\n",
      "    76.52359771728516,\n",
      "    -111.13126373291016,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm010: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    77.65929412841797,\n",
      "    -72.13126373291016\n",
      "  ],\n",
      "  mm001: Float32Array(3) [\n",
      "    -76.13126373291016,\n",
      "    -111.13126373291016,\n",
      "    86.42330169677734\n",
      "  ],\n",
      "  dimsRAS: [ 3, 207, 256, 215 ],\n",
      "  pixDimsRAS: [ 1, 0.737463116645813, 0.737463116645813, 0.737463116645813 ],\n",
      "  permRAS: [ 1, 2, 3 ],\n",
      "  toRAS: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  matRAS: Float32Array(16) [\n",
      "    0.737463116645813,                   0,\n",
      "                    0,  -75.76253509521484,\n",
      "                    0,   0.737463116645813,\n",
      "                    0, -110.76253509521484,\n",
      "                    0,                   0,\n",
      "    0.737463116645813,  -71.76253509521484,\n",
      "                    0,                   0,\n",
      "                    0,                   1\n",
      "  ],\n",
      "  oblique_angle: 0,\n",
      "  obliqueRAS: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  maxShearDeg: 0,\n",
      "  frac2mm: Float32Array(16) [\n",
      "     152.6548614501953,                   0,\n",
      "                     0,                   0,\n",
      "                     0,  188.79055786132812,\n",
      "                     0,                   0,\n",
      "                     0,                   0,\n",
      "     158.5545654296875,                   0,\n",
      "    -76.13126373291016, -111.13126373291016,\n",
      "    -72.13126373291016,                   1\n",
      "  ],\n",
      "  frac2mmOrtho: Float32Array(16) [\n",
      "     152.6548614501953,                   0,\n",
      "                     0,                   0,\n",
      "                     0,  188.79055786132812,\n",
      "                     0,                   0,\n",
      "                     0,                   0,\n",
      "     158.5545654296875,                   0,\n",
      "    -76.13127136230469, -111.13126373291016,\n",
      "    -72.13126373291016,                   1\n",
      "  ],\n",
      "  extentsMinOrtho: [ -76.13127136230469, -111.13126373291016, -72.13126373291016 ],\n",
      "  extentsMaxOrtho: [ 76.52359008789062, 77.65929412841797, 86.42330169677734 ],\n",
      "  mm2ortho: Float32Array(16) [\n",
      "    1, 0, 0, 0, 0, 1,\n",
      "    0, 0, 0, 0, 1, 0,\n",
      "    0, 0, 0, 1\n",
      "  ],\n",
      "  cal_min: 40,\n",
      "  cal_max: 80,\n",
      "  robust_min: 40,\n",
      "  robust_max: 80,\n",
      "  global_min: 40,\n",
      "  global_max: 80,\n",
      "  url: 'https://niivue.github.io/niivue-demo-images/mni152.nii.gz'\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "// in kernel, The configuration runs using node, and not in the browser,\n",
    "// which is why window is not defined\n",
    "// we need to define it to make the code work\n",
    "\n",
    "// global.window = { navigator: { userAgent: 'node.js' } };\n",
    "\n",
    "import crypto from \"node:crypto\";\n",
    "global.crypto ??= crypto;\n",
    "const volume = await NVImage.loadFromUrl({url:\"https://niivue.github.io/niivue-demo-images/mni152.nii.gz\"})\n",
    "console.log(volume)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "function getMax(arr) {\n",
    "    let len = arr.length;\n",
    "    let max = -Infinity;\n",
    "\n",
    "    while (len--) {\n",
    "        max = arr[len] > max ? arr[len] : max;\n",
    "    }\n",
    "    return max;\n",
    "}\n",
    "\n",
    "function getMin(arr) {\n",
    "    let len = arr.length;\n",
    "    let min = Infinity;\n",
    "\n",
    "    while (len--) {\n",
    "        min = arr[len] < min ? arr[len] : min;\n",
    "    }\n",
    "    return min;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "function normalizeArray(\n",
    "    array: Float32Array | Uint8Array,\n",
    "    max: number\n",
    "  ): Float32Array {\n",
    "    let normalizedArray = new Float32Array(array.length);\n",
    "    for (let i = 0; i < array.length; i++) {\n",
    "      normalizedArray[i] = array[i] / max;\n",
    "    }\n",
    "    return normalizedArray;\n",
    "  }\n",
    "  \n",
    "  function stackSliceToRGB(\n",
    "    buffer: Float32Array | Uint8Array,\n",
    "  ): Float32Array {\n",
    "    let bufferLength = buffer.length,\n",
    "      result = new Float32Array(bufferLength * 3);\n",
    "  \n",
    "    for (let i = 0; i < bufferLength; i++) {\n",
    "      result[3 * i] = buffer[i];\n",
    "      result[3 * i + 1] = buffer[i];\n",
    "      result[3 * i + 2] = buffer[i];\n",
    "    }\n",
    "    return result;\n",
    "  }\n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "const preprocessVolume = (image) => {\n",
    "    try {\n",
    "      const imageRAS = image.img2RAS();\n",
    "      // console.log(\"image.calMax, image.calMin \", image.global_max, image.global_min);\n",
    "      const maxVal = getMax(imageRAS);\n",
    "      const normalizedArray = normalizeArray(imageRAS, maxVal);\n",
    "      console.log(\"normalizedArray \", normalizedArray.reduce((a, b) => a + b, 0));\n",
    "      return normalizedArray;\n",
    "    } catch (e) {\n",
    "      console.log(`failed to preprocess volume: ${e}. `);\n",
    "      throw Error(`failed to preprocess volume: ${e}. `);\n",
    "    }\n",
    "  }\n",
    "\n",
    "const preprocess = (slice2D: Float32Array, sliceId: number, width: number, height: number): Float32Array => {\n",
    "    try {\n",
    "      // console.log(\"imageArray \", slice2D);\n",
    "      let image3Channels: Float32Array;\n",
    "      const sliceArray = slice2D.slice(\n",
    "        width * height * sliceId,\n",
    "        width * height * (sliceId + 1),\n",
    "      );\n",
    "      console.log(\"sliceArray \", sliceArray.reduce((a, b) => a + b, 0));\n",
    "  \n",
    "      image3Channels = stackSliceToRGB(sliceArray);\n",
    "      console.log(\"image3Channels \", image3Channels, image3Channels.reduce((a, b) => a + b, 0));\n",
    "      return image3Channels;\n",
    "    } catch (e) {\n",
    "      console.log(`failed to inference ONNX model: ${e}. `);\n",
    "      throw Error(`failed to inference ONNX model: ${e}. `);\n",
    "    }\n",
    "};\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sliceArray  6478747\n",
      "image3Channels  Float32Array(158976) [\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0,\n",
      "  ... 158876 more items\n",
      "] 19436241\n"
     ]
    }
   ],
   "source": [
    "let stack_processed = preprocess(volume.img2RAS(), 90, dims[0], dims[1]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uint8Array(10) [\n",
      "  0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0\n",
      "]\n",
      "Mat {}\n"
     ]
    }
   ],
   "source": [
    "imagedataToImage(stack_processed, [dims[0], dims[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "function imagedataToImage(imagedata: Float32Array | Uint8Array, dims: number[]) {\n",
    "    let inputImage;\n",
    "    // if (dims[0]*dims[1] !== imagedata.length) {\n",
    "    //     throw new Error(\"Image data size does not match the dimensions\");\n",
    "    // }\n",
    "\n",
    "      inputImage = new Uint8Array(dims[0]*dims[1]*3);\n",
    "      for (let i=0; i<imagedata.length; i++) {\n",
    "        inputImage[i] = imagedata[i]*255;\n",
    "    }\n",
    "\n",
    "    let dst = cv.matFromArray(dims[0], dims[1], cv.CV_8UC3, inputImage);\n",
    "    console.log(dst.data.slice(600, 610));\n",
    "    console.log(dst);\n",
    "    new Jimp({\n",
    "        width: dims[0],\n",
    "        height: dims[1],\n",
    "        data: Buffer.from(dst.data)\n",
    "    }).write('./niivue.png');\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "function nvVolumetoSlice(volume, dims, fov, index): any {\n",
    "    let sliceArray;\n",
    "    switch (fov) {\n",
    "        // sagittal dimsRAS[1], coronal dimsRAS[2], axial dimsRAS[3]\n",
    "        \n",
    "        // 1. if axial, slice the array from volume\n",
    "        case \"axial\":\n",
    "            sliceArray = volume.slice(\n",
    "                dims[0] * dims[1] * index,\n",
    "                dims[0] * dims[1] * (index + 1),\n",
    "            );\n",
    "            console.log(\"axial sliceArray\",dims[1], dims[2], index, sliceArray.length);\n",
    "        // 2. if coronal, \n",
    "        case \"coronal\":\n",
    "        // 3. if sagittal,\n",
    "        case \"sagittal\":\n",
    "    }\n",
    "    return sliceArray;\n",
    "    \n",
    "}\n",
    "\n",
    "function nvSliceToTensor(nvSlice, dims): any {\n",
    "    console.log(\"nvSlice\", nvSlice.length);\n",
    "    // 1. preprocess\n",
    "    let image3Channels = stackSliceToRGB(nvSlice);\n",
    "    // 2. convert to float32\n",
    "    console.log(\"image3Channels\", image3Channels.length);\n",
    "    // 3. tensor\n",
    "    const inputTensor = new Tensor(\"float32\", image3Channels, dims);\n",
    "    return inputTensor;\n",
    "}\n",
    "\n",
    "function imageDataToTensor(data, dims, max){\n",
    "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
    "    const [R, G, B]: number[][] = [[], [], []];\n",
    "    for (let i = 0; i < data.length; i += 3) {\n",
    "      R.push(data[i]);\n",
    "      G.push(data[i + 1]);\n",
    "      B.push(data[i + 2]);\n",
    "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
    "    }\n",
    "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
    "    const transposedData = R.concat(G).concat(B);\n",
    "  \n",
    "    // 3. convert to float32\n",
    "    let i, l = transposedData.length; // length, we need this for the loop\n",
    "    const float32Data = new Float32Array(dims[3]*dims[1]*dims[2]); // create the Float32Array for output\n",
    "    for (i = 0; i < l; i++) {\n",
    "      float32Data[i] = transposedData[i] / 252.0; // convert to float\n",
    "    }\n",
    "  \n",
    "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
    "    return inputTensor;\n",
    "  }\n",
    "\n",
    "function arrayToTensor(array, dims){\n",
    "    let float32Data = new Float32Array(array.length*3);\n",
    "    for (let i = 0; i < array.length; i++) {\n",
    "        float32Data[i] = array[i];\n",
    "        float32Data[i + array.length] = array[i];\n",
    "        float32Data[i + 2 * array.length] = array[i];\n",
    "    }\n",
    "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
    "    return inputTensor;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normalizedArray  3269611.783972291\n",
      "axial sliceArray 256 215 90 52992\n",
      "nvSlice 52992\n",
      "image3Channels 158976\n"
     ]
    }
   ],
   "source": [
    "const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
    "let nvVolume = preprocessVolume(volume);\n",
    "let nvSlice = nvVolumetoSlice(nvVolume, dims, \"axial\", 90);\n",
    "let inputTensor = nvSliceToTensor(nvSlice, [1, 3, dims[0], dims[1]]);\n",
    "const maxVal = getMax(volume.img2RAS());\n",
    "let transposedTensor = imageDataToTensor(inputTensor.data, [1, 3, dims[0], dims[1]], maxVal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32Array(7) [\n",
      "  0.4246031641960144,\n",
      "  0.4246031641960144,\n",
      "  0.2936508059501648,\n",
      "  0.2936508059501648,\n",
      "  0.2936508059501648,\n",
      "  0.1626984179019928,\n",
      "  0.1626984179019928\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "inputTensor.data.slice(16000,16007)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "axial sliceArray 256 215 90 52992\n"
     ]
    }
   ],
   "source": [
    "// const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
    "// // let nvVolume = preprocessVolume(volume);\n",
    "// let nvSlice = nvVolumetoSlice(volume.img2RAS(), dims, \"axial\", 90);\n",
    "// // let inputImage = nvSliceToImage(nvSlice);\n",
    "// const maxVal = getMax(volume.img2RAS());\n",
    "// let inputTensor = arrayToTensor(nvSlice, [1, 3, dims[0], dims[1]], maxVal);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uint8Array(10) [\n",
      "  0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0\n",
      "]\n",
      "Mat {}\n"
     ]
    }
   ],
   "source": [
    "imagedataToImage(inputTensor.data, [dims[0], dims[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "77127.94049503142 [ 1, 3, 207, 256 ] 0.932539701461792 0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "823942169 252 0 80 40\n"
     ]
    }
   ],
   "source": [
    "console.log(inputTensor.data.reduce((a,b) => a+b,0), inputTensor.dims, getMax(inputTensor.data), getMin(inputTensor.data));\n",
    "\n",
    "console.log(volume.img2RAS().reduce((a,b) => a+b, 0), getMax(volume.img), getMin(volume.img), volume.global_max, volume.global_min);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "global.self = global;\n",
    "env.wasm.numThreads = 1;\n",
    "\n",
    "const encoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_encoder.onnx');\n",
    "const decoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_decoder.onnx');\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "async function runEncoder(model, preprocessedData): Promise<[Tensor, number]> {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "      const feeds: Record<string, Tensor> = {};\n",
    "      feeds[model.inputNames[0]] = preprocessedData;\n",
    "      const outputData = await model.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[model.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }\n",
    "\n",
    "async function runDecoder(model, embedding, inputPoints, inputLabels, oriSize): Promise<[Tensor, number]> {\n",
    "  const decoderStart = new Date();\n",
    "  try {\n",
    "    const decoderFeeds: Record<string, Tensor> = {};\n",
    "    console.log(\"model.inputNames\", model.inputNames)\n",
    "    decoderFeeds[model.inputNames[0]] = embedding;\n",
    "    decoderFeeds[model.inputNames[1]] = inputPoints;\n",
    "    decoderFeeds[model.inputNames[2]] = inputLabels;\n",
    "    decoderFeeds[model.inputNames[3]] = oriSize;\n",
    "\n",
    "    // feeds[model.inputNames[1]] = new Tensor(\"float32\", inputPoints, [1, 1, inputPoints.length/2, 2]);\n",
    "    // feeds[model.inputNames[2]] = new Tensor(\"float32\", new Array(inputPoints.length/2).fill(1), inputPoints.length/2);\n",
    "    // feeds[model.inputNames[3]] = new Tensor(\"int64\", oriSize);\n",
    "    const outputData = await model.run(decoderFeeds);\n",
    "    const decoderEnd = new Date();\n",
    "    const decoderInferenceTime = (decoderEnd.getTime() - decoderStart.getTime());\n",
    "    const decoderOutput = outputData[model.outputNames[0]];\n",
    "    return [decoderOutput, decoderInferenceTime];\n",
    "  } catch (e) {\n",
    "    console.error(e);\n",
    "    throw new Error();\n",
    "  }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "const [embedding, encoderTime] =  await runEncoder(encoderSession, inputTensor);\n",
    "var encoderOutput = embedding.data;\n",
    "var inferenceTime = encoderTime;\n",
    "// var results = softmax(Array.prototype.slice.call(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1811.537114978095 10161\n"
     ]
    }
   ],
   "source": [
    "console.log((encoderOutput as Float32Array).reduce((a,b) => a + b, 0), inferenceTime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model.inputNames [\n",
      "  'image_embeddings',\n",
      "  'batched_point_coords',\n",
      "  'batched_point_labels',\n",
      "  'orig_im_size'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "let points = new Float32Array([34, 150, 35, 150])\n",
    "let labels = new Float32Array(points.length/2).fill(1)\n",
    "let pointsTensor = new Tensor(\"float32\", points, [1, 1, 2, 2]);\n",
    "let labelsTensor = new Tensor(\"float32\", labels, [1,1,labels.length]);\n",
    "let originalSize = new Tensor(\"int64\", [dims[0], dims[1]], [2]);\n",
    "const [mask, decoderTime] = await runDecoder(decoderSession, embedding, pointsTensor, labelsTensor, originalSize);\n",
    "var decoderOutput = mask.data;\n",
    "var inferenceTime = decoderTime;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "function transposeChannel(data, dims) {\n",
    "    let transposedData = new Float32Array(dims[3]*dims[4]*dims[2]);\n",
    "    const channelLength = dims[3]*dims[4];\n",
    "    for (let i = 0; i < data.length; i+=3) {\n",
    "        transposedData[i] = data[i];\n",
    "        transposedData[i+1] = data[i+channelLength];\n",
    "        transposedData[i+2] = data[i+2*channelLength];\n",
    "    }\n",
    "    return transposedData;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32Array(158976) [\n",
      "  -0.35261034965515137,   -0.357004314661026, -0.14563128352165222,\n",
      "   -0.1738205999135971, -0.20448988676071167, -0.21276701986789703,\n",
      "  -0.20582811534404755, -0.21688145399093628, -0.18029552698135376,\n",
      "  -0.19248846173286438, -0.19351686537265778,  -0.2097848504781723,\n",
      "   -0.1618129163980484, -0.18173974752426147, -0.20316855609416962,\n",
      "  -0.22348643839359283,  -0.1598932296037674, -0.19097548723220825,\n",
      "   -0.2209727168083191,  -0.2352137416601181, -0.15838882327079773,\n",
      "   -0.1931561976671219,  -0.2211531400680542, -0.23099099099636078,\n",
      "  -0.15211433172225952,  -0.1923026442527771, -0.21370403468608856,\n",
      "  -0.22706826031208038, -0.14434345066547394, -0.18436533212661743,\n",
      "  -0.20926396548748016, -0.22062653303146362,  -0.1562342643737793,\n",
      "  -0.18869848549365997, -0.21952533721923828,  -0.2312026172876358,\n",
      "  -0.16751091182231903, -0.19559451937675476,  -0.2177271842956543,\n",
      "  -0.24237291514873505, -0.18587234616279602, -0.21461135149002075,\n",
      "  -0.22676952183246613,  -0.2554420530796051, -0.20899781584739685,\n",
      "  -0.23542211949825287, -0.22466713190078735,  -0.2555462718009949,\n",
      "   -0.2143225371837616, -0.24015289545059204, -0.21517600119113922,\n",
      "   -0.2517086863517761,  -0.1998416781425476, -0.22918960452079773,\n",
      "  -0.19342075288295746,  -0.2363603711128235, -0.15120744705200195,\n",
      "  -0.18186821043491364,  -0.1625727266073227, -0.19998063147068024,\n",
      "  -0.14898565411567688, -0.18370674550533295,  -0.1449977159500122,\n",
      "  -0.18562215566635132, -0.11825720220804214, -0.16692622005939484,\n",
      "  -0.17951038479804993, -0.19939929246902466,  -0.1930282562971115,\n",
      "   -0.2053665816783905, -0.17144355177879333,  -0.2257731854915619,\n",
      "  -0.18532900512218475, -0.21410737931728363, -0.18225722014904022,\n",
      "  -0.24324250221252441, -0.18980422616004944, -0.22672423720359802,\n",
      "  -0.16136932373046875, -0.23460043966770172, -0.16474591195583344,\n",
      "  -0.19206613302230835, -0.13742418587207794, -0.20048382878303528,\n",
      "  -0.14152683317661285,  -0.1721239984035492,   -0.130048468708992,\n",
      "  -0.18966299295425415,  -0.1398657113313675, -0.17250922322273254,\n",
      "  -0.13263997435569763, -0.19303835928440094, -0.15858721733093262,\n",
      "  -0.19282475113868713, -0.14492687582969666, -0.20919105410575867,\n",
      "  -0.19198104739189148,  -0.2286103367805481, -0.16698376834392548,\n",
      "   -0.2223130762577057,\n",
      "  ... 158876 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "decoderOutput"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32Array(158976) [\n",
      "  -0.35261034965515137, -31.931503295898438,  -4.792166709899902,\n",
      "   -0.1738205999135971,  -34.34942626953125, -5.2030110359191895,\n",
      "  -0.20582811534404755,  -34.80441665649414,  -5.148431301116943,\n",
      "  -0.19248846173286438,  -33.82314682006836,  -4.973199367523193,\n",
      "   -0.1618129163980484,  -33.84146499633789,  -4.893842697143555,\n",
      "  -0.22348643839359283,  -34.55813217163086,  -5.150190830230713,\n",
      "   -0.2209727168083191, -33.819557189941406,  -5.047060966491699,\n",
      "   -0.1931561976671219, -32.258209228515625,  -4.824119567871094,\n",
      "  -0.15211433172225952, -32.487911224365234,  -4.772770404815674,\n",
      "  -0.22706826031208038, -33.720706939697266,  -5.021378040313721,\n",
      "  -0.20926396548748016, -33.366371154785156,  -4.936467170715332,\n",
      "  -0.18869848549365997,  -32.77333068847656, -4.7943806648254395,\n",
      "  -0.16751091182231903,   -32.9053955078125, -4.6888251304626465,\n",
      "  -0.24237291514873505,  -33.23194122314453,  -4.802729606628418,\n",
      "  -0.22676952183246613,   -33.2132453918457, -4.7687296867370605,\n",
      "  -0.23542211949825287,  -32.19513702392578,  -4.661533355712891,\n",
      "   -0.2143225371837616, -31.894567489624023,  -4.579400062561035,\n",
      "   -0.2517086863517761, -31.393848419189453,  -4.593441486358643,\n",
      "  -0.19342075288295746, -31.652036666870117,   -4.58205509185791,\n",
      "  -0.18186821043491364, -30.388080596923828,  -4.486503601074219,\n",
      "  -0.14898565411567688, -31.015485763549805,  -4.466778755187988,\n",
      "  -0.18562215566635132,  -30.62804412841797,  -4.521280288696289,\n",
      "  -0.17951038479804993,  -32.41441345214844,  -4.643962383270264,\n",
      "   -0.2053665816783905, -31.752546310424805, -4.5821356773376465,\n",
      "  -0.18532900512218475, -31.115734100341797, -4.4924845695495605,\n",
      "  -0.24324250221252441, -30.872161865234375,  -4.459438323974609,\n",
      "  -0.16136932373046875, -31.647836685180664, -4.4738874435424805,\n",
      "  -0.19206613302230835, -31.803499221801758,  -4.463320732116699,\n",
      "  -0.14152683317661285, -32.154457092285156,  -4.477398872375488,\n",
      "  -0.18966299295425415,  -33.07418441772461,  -4.520135879516602,\n",
      "  -0.13263997435569763,  -33.53299331665039, -4.6193671226501465,\n",
      "  -0.19282475113868713, -32.263267517089844,  -4.659881114959717,\n",
      "  -0.19198104739189148, -32.039432525634766,  -4.729679584503174,\n",
      "   -0.2223130762577057,\n",
      "  ... 158876 more items\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "transposedMask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "let transposedMask = transposeChannel(decoderOutput, mask.dims);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "let maskImage = new Uint8Array(dims[0]*dims[1]*3);\n",
    "for (let i=0; i<transposedMask.length; i++) {\n",
    "    if (transposedMask[i] >= 0) {\n",
    "        maskImage[i] = 255;\n",
    "    } else {\n",
    "        maskImage[i] = 0;\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uint8Array(10) [\n",
      "  0, 0, 0, 0, 0,\n",
      "  0, 0, 0, 0, 0\n",
      "]\n",
      "Mat {}\n"
     ]
    }
   ],
   "source": [
    "imagedataToImage((maskImage).slice(dims[0]*dims[1]), [dims[0], dims[1]]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1811852.2913827675\n"
     ]
    }
   ],
   "source": [
    "(decoderOutput as Float32Array).reduce((a,b) => a + b, 0)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TypeScript",
   "language": "typescript",
   "name": "tslab"
  },
  "language_info": {
   "codemirror_mode": {
    "mode": "typescript",
    "name": "javascript",
    "typescript": true
   },
   "file_extension": ".ts",
   "mimetype": "text/typescript",
   "name": "typescript",
   "version": "3.7.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a10bf6accb374a6da2204700f697d150b0507c8791e988710f45c7e1f2c02832"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
