{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creating a 3D array of size (2, 9, 5)**\n",
        "```python\n",
        "array_3d = np.array([\n",
        "    [\n",
        "        [1, 2, 3, 4, 5],\n",
        "        [6, 7, 8, 9, 10],\n",
        "        [41, 42, 43, 44, 45]\n",
        "    ],\n",
        "    [\n",
        "        [46, 47, 48, 49, 50],\n",
        "        [81, 82, 83, 84, 85],\n",
        "        [86, 87, 88, 89, 90]\n",
        "    ]\n",
        "])\n",
        "```\n",
        "\n",
        "**Get flatten array from index [:,:,1]**\n",
        "```python\n",
        "array_3d[:,:,1].flatten() \n",
        "```\n",
        "\n",
        "[ 2  7 42 47 82 87]\n",
        "\n",
        "=**Get flatten array from index [:,1,:]**\n",
        "```python\n",
        "array_3d[:,1,:].flatten()\n",
        "```\n",
        "\n",
        "[ 6  7  8  9 10 81 82 83 84 85]\n",
        "\n",
        "**Get flatten array from index [1,:,:]**\n",
        "```python\n",
        "array_3d[1,:,:].flatten()\n",
        "```\n",
        "\n",
        "[46 47 48 49 50 81 82 83 84 85 86 87 88 89 90]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import {InferenceSession, Tensor, env} from 'onnxruntime-web';\n",
        "const ndarray = require('ndarray')\n",
        "const ops = require('ndarray-ops')\n",
        "const fs = require('fs')\n",
        "import Jimp from \"jimp\";\n",
        "import { Niivue, NVImage } from \"@niivue/niivue\";\n",
        "import { cv } from \"opencv-wasm\";\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uint8Array(11393280) [\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0,\n",
            "  ... 11393180 more items\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "// in kernel, The configuration runs using node, and not in the browser,\n",
        "// which is why window is not defined\n",
        "// we need to define it to make the code work\n",
        "\n",
        "// global.window = { navigator: { userAgent: 'node.js' } };\n",
        "\n",
        "import crypto from \"node:crypto\";\n",
        "global.crypto ??= crypto;\n",
        "const volume = await NVImage.loadFromUrl({url:\"https://niivue.github.io/niivue-demo-images/mni152.nii.gz\"})\n",
        "console.log(volume.img)\n",
        "\n",
        "// import fs from 'fs';\n",
        "\n",
        "// const writeStream = fs.createWriteStream('file.txt');\n",
        "// const pathName = writeStream.path;\n",
        "  \n",
        "// // write each value of the array on the file breaking line\n",
        "// volume.img.forEach(value => writeStream.write(`${value}\\n`));\n",
        "\n",
        "// // the finish event is emitted when all data has been flushed from the stream\n",
        "// writeStream.on('finish', () => {\n",
        "//    console.log(`wrote all the array data to file ${pathName}`);\n",
        "// });\n",
        "\n",
        "// // handle the errors on the write process\n",
        "// writeStream.on('error', (err) => {\n",
        "//     console.error(`There is an error writing the file ${pathName} => ${err}`)\n",
        "// });\n",
        "\n",
        "// // close the stream\n",
        "// writeStream.end();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function getMax(arr) {\n",
        "    let len = arr.length;\n",
        "    let max = -Infinity;\n",
        "\n",
        "    while (len--) {\n",
        "        max = arr[len] > max ? arr[len] : max;\n",
        "    }\n",
        "    return max;\n",
        "}\n",
        "\n",
        "function getMin(arr) {\n",
        "    let len = arr.length;\n",
        "    let min = Infinity;\n",
        "\n",
        "    while (len--) {\n",
        "        min = arr[len] < min ? arr[len] : min;\n",
        "    }\n",
        "    return min;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "function normalizeArray(\n",
        "    array: Float32Array | Uint8Array,\n",
        "    max: number\n",
        "  ): Float32Array {\n",
        "    let normalizedArray = new Float32Array(array.length);\n",
        "    for (let i = 0; i < array.length; i++) {\n",
        "      normalizedArray[i] = array[i] / max;\n",
        "    }\n",
        "    return normalizedArray;\n",
        "  }\n",
        "  \n",
        "  function stackSliceToRGB(\n",
        "    buffer: Float32Array | Uint8Array,\n",
        "  ): Float32Array {\n",
        "    let bufferLength = buffer.length,\n",
        "      result = new Float32Array(bufferLength * 3);\n",
        "  \n",
        "    for (let i = 0; i < bufferLength; i++) {\n",
        "      result[3 * i] = buffer[i];\n",
        "      result[3 * i + 1] = buffer[i];\n",
        "      result[3 * i + 2] = buffer[i];\n",
        "    }\n",
        "    return result;\n",
        "  }\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "const preprocessVolume = (image) => {\n",
        "    try {\n",
        "      const imageRAS = image.img2RAS();\n",
        "      // console.log(\"image.calMax, image.calMin \", image.global_max, image.global_min);\n",
        "      const maxVal = getMax(imageRAS);\n",
        "      const normalizedArray = normalizeArray(imageRAS, maxVal);\n",
        "      console.log(\"normalizedArray \", normalizedArray.reduce((a, b) => a + b, 0));\n",
        "      return normalizedArray;\n",
        "    } catch (e) {\n",
        "      console.log(`failed to preprocess volume: ${e}. `);\n",
        "      throw Error(`failed to preprocess volume: ${e}. `);\n",
        "    }\n",
        "  }\n",
        "\n",
        "const preprocess = (slice2D: Float32Array, sliceId: number, width: number, height: number): Float32Array => {\n",
        "    try {\n",
        "      // console.log(\"imageArray \", slice2D);\n",
        "      let image3Channels: Float32Array;\n",
        "      const sliceArray = slice2D.slice(\n",
        "        width * height * sliceId,\n",
        "        width * height * (sliceId + 1),\n",
        "      );\n",
        "      console.log(\"sliceArray \", sliceArray.reduce((a, b) => a + b, 0));\n",
        "  \n",
        "      image3Channels = stackSliceToRGB(sliceArray);\n",
        "      console.log(\"image3Channels \", image3Channels, image3Channels.reduce((a, b) => a + b, 0));\n",
        "      return image3Channels;\n",
        "    } catch (e) {\n",
        "      console.log(`failed to inference ONNX model: ${e}. `);\n",
        "      throw Error(`failed to inference ONNX model: ${e}. `);\n",
        "    }\n",
        "};\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "function imagedataToImage(imagedata: Float32Array | Uint8Array, dims: number[]) {\n",
        "    let inputImage;\n",
        "    // if (dims[0]*dims[1] !== imagedata.length) {\n",
        "    //     throw new Error(\"Image data size does not match the dimensions\");\n",
        "    // }\n",
        "\n",
        "      inputImage = new Uint8Array(dims[0]*dims[1]*3);\n",
        "      for (let i=0; i<imagedata.length; i++) {\n",
        "        inputImage[i] = imagedata[i]*255;\n",
        "    }\n",
        "\n",
        "    let dst = cv.matFromArray(dims[0], dims[1], cv.CV_8UC3, inputImage);\n",
        "    console.log(dst.data.slice(600, 610));\n",
        "    console.log(dst);\n",
        "    new Jimp({\n",
        "        width: dims[0],\n",
        "        height: dims[1],\n",
        "        data: Buffer.from(dst.data)\n",
        "    }).write('./niivue.png');\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "function nvVolumetoSlice(volume, dims, fov, index): any {\n",
        "    let sliceArray;\n",
        "    switch (fov) {\n",
        "        // sagittal dimsRAS[1], coronal dimsRAS[2], axial dimsRAS[3]\n",
        "        \n",
        "        // 1. if axial, slice the array from volume\n",
        "        case \"axial\":\n",
        "            sliceArray = volume.slice(\n",
        "                dims[0] * dims[1] * index,\n",
        "                dims[0] * dims[1] * (index + 1),\n",
        "            );\n",
        "            console.log(\"axial sliceArray\",dims[1], dims[2], index, sliceArray.length);\n",
        "        // 2. if coronal, \n",
        "        case \"coronal\":\n",
        "        // 3. if sagittal,\n",
        "        case \"sagittal\":\n",
        "    }\n",
        "    return sliceArray;\n",
        "    \n",
        "}\n",
        "\n",
        "function nvSliceToTensor(nvSlice, dims): any {\n",
        "    console.log(\"nvSlice\", nvSlice.length);\n",
        "    // 1. preprocess\n",
        "    let image3Channels = stackSliceToRGB(nvSlice);\n",
        "    // 2. convert to float32\n",
        "    console.log(\"image3Channels\", image3Channels.length);\n",
        "    // 3. tensor\n",
        "    const inputTensor = new Tensor(\"float32\", image3Channels, dims);\n",
        "    return inputTensor;\n",
        "}\n",
        "\n",
        "function imageDataToTensor(data, dims, max): any {\n",
        "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
        "    const [R, G, B]: number[][] = [[], [], []];\n",
        "    for (let i = 0; i < data.length; i += 3) {\n",
        "      R.push(data[i]);\n",
        "      G.push(data[i + 1]);\n",
        "      B.push(data[i + 2]);\n",
        "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
        "    }\n",
        "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
        "    const transposedData = R.concat(G).concat(B);\n",
        "  \n",
        "    // 3. convert to float32\n",
        "    let i, l = transposedData.length; // length, we need this for the loop\n",
        "    const float32Data = new Float32Array(dims[3]*dims[1]*dims[2]); // create the Float32Array for output\n",
        "    for (i = 0; i < l; i++) {\n",
        "      float32Data[i] = transposedData[i] ; // divide by max value to convert to float\n",
        "    }\n",
        "  \n",
        "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
        "    return inputTensor;\n",
        "  }\n",
        "\n",
        "function arrayToTensor(array, dims): any {\n",
        "    let float32Data = new Float32Array(array.length*3);\n",
        "    for (let i = 0; i < array.length; i++) {\n",
        "        float32Data[i] = array[i];\n",
        "        float32Data[i + array.length] = array[i];\n",
        "        float32Data[i + 2 * array.length] = array[i];\n",
        "    }\n",
        "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
        "    return inputTensor;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizedArray  3269611.783972291\n",
            "axial sliceArray 256 215 90 52992\n",
            "nvSlice 52992\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image3Channels 158976\n"
          ]
        }
      ],
      "source": [
        "const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
        "let nvVolume = preprocessVolume(volume);\n",
        "let nvSlice = nvVolumetoSlice(nvVolume, dims, \"axial\", 90);\n",
        "let inputTensor = nvSliceToTensor(nvSlice, [1, 3, dims[0], dims[1]]);\n",
        "const maxVal = getMax(volume.img2RAS());\n",
        "let transposedTensor = imageDataToTensor(inputTensor.data, [1, 3, dims[1], dims[0]], maxVal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Float32Array(7) [\n",
            "  0.4246031641960144,\n",
            "  0.4246031641960144,\n",
            "  0.2936508059501648,\n",
            "  0.2936508059501648,\n",
            "  0.2936508059501648,\n",
            "  0.1626984179019928,\n",
            "  0.1626984179019928\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "inputTensor.data.slice(16000,16007)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "axial sliceArray 256 215 90 52992\n"
          ]
        }
      ],
      "source": [
        "// const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
        "// // let nvVolume = preprocessVolume(volume);\n",
        "// let nvSlice = nvVolumetoSlice(volume.img2RAS(), dims, \"axial\", 90);\n",
        "// // let inputImage = nvSliceToImage(nvSlice);\n",
        "// const maxVal = getMax(volume.img2RAS());\n",
        "// let inputTensor = arrayToTensor(nvSlice, [1, 3, dims[0], dims[1]], maxVal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uint8Array(10) [\n",
            "  0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0\n",
            "]\n",
            "Mat {}\n"
          ]
        }
      ],
      "source": [
        "imagedataToImage(inputTensor.data, [dims[0], dims[1]]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77127.94049503142 [ 1, 3, 256, 207 ] 0.932539701461792 0\n",
            "823942169 252 0 80 40\n"
          ]
        }
      ],
      "source": [
        "console.log(transposedTensor.data.reduce((a,b) => a+b,0), transposedTensor.dims, getMax(transposedTensor.data), getMin(transposedTensor.data));\n",
        "\n",
        "console.log(volume.img2RAS().reduce((a,b) => a+b, 0), getMax(volume.img), getMin(volume.img), volume.global_max, volume.global_min);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77127.94049503142 [ 1, 3, 256, 207 ] 0.932539701461792 0\n",
            "823942169 252 0 80 40\n"
          ]
        }
      ],
      "source": [
        "console.log(inputTensor.data.reduce((a,b) => a+b,0), inputTensor.dims, getMax(inputTensor.data), getMin(inputTensor.data));\n",
        "\n",
        "console.log(volume.img2RAS().reduce((a,b) => a+b, 0), getMax(volume.img), getMin(volume.img), volume.global_max, volume.global_min);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [],
      "source": [
        "global.self = global;\n",
        "env.wasm.numThreads = 1;\n",
        "\n",
        "const encoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_encoder.onnx');\n",
        "const decoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_decoder.onnx');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "async function runEncoder(model, preprocessedData): Promise<[Tensor, number]> {\n",
        "    const start = new Date();\n",
        "    try {\n",
        "      const feeds: Record<string, Tensor> = {};\n",
        "      feeds[model.inputNames[0]] = preprocessedData;\n",
        "      const outputData = await model.run(feeds);\n",
        "      const end = new Date();\n",
        "      const inferenceTime = (end.getTime() - start.getTime());\n",
        "      const output = outputData[model.outputNames[0]];\n",
        "      return [output, inferenceTime];\n",
        "    } catch (e) {\n",
        "      console.error(e);\n",
        "      throw new Error();\n",
        "    }\n",
        "  }\n",
        "\n",
        "async function runDecoder(model, embedding, inputPoints, inputLabels, oriSize): Promise<[Tensor, number]> {\n",
        "  const decoderStart = new Date();\n",
        "  try {\n",
        "    const decoderFeeds: Record<string, Tensor> = {};\n",
        "    console.log(\"model.inputNames\", model.inputNames)\n",
        "    decoderFeeds[model.inputNames[0]] = embedding;\n",
        "    decoderFeeds[model.inputNames[1]] = inputPoints;\n",
        "    decoderFeeds[model.inputNames[2]] = inputLabels;\n",
        "    decoderFeeds[model.inputNames[3]] = oriSize;\n",
        "\n",
        "    // feeds[model.inputNames[1]] = new Tensor(\"float32\", inputPoints, [1, 1, inputPoints.length/2, 2]);\n",
        "    // feeds[model.inputNames[2]] = new Tensor(\"float32\", new Array(inputPoints.length/2).fill(1), inputPoints.length/2);\n",
        "    // feeds[model.inputNames[3]] = new Tensor(\"int64\", oriSize);\n",
        "    const outputData = await model.run(decoderFeeds);\n",
        "    const decoderEnd = new Date();\n",
        "    const decoderInferenceTime = (decoderEnd.getTime() - decoderStart.getTime());\n",
        "    const decoderOutput = outputData[model.outputNames[0]];\n",
        "    return [decoderOutput, decoderInferenceTime];\n",
        "  } catch (e) {\n",
        "    console.error(e);\n",
        "    throw new Error();\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "const [embedding, encoderTime] =  await runEncoder(encoderSession, transposedTensor);\n",
        "var encoderOutput = embedding.data;\n",
        "var inferenceTime = encoderTime;\n",
        "// var results = softmax(Array.prototype.slice.call(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2118.37974857889 5364\n"
          ]
        }
      ],
      "source": [
        "console.log((encoderOutput as Float32Array).reduce((a,b) => a + b, 0), inferenceTime);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.inputNames [\n",
            "  'image_embeddings',\n",
            "  'batched_point_coords',\n",
            "  'batched_point_labels',\n",
            "  'orig_im_size'\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "let points = new Float32Array([134, 150])\n",
        "let labels = new Float32Array(points.length/2).fill(1)\n",
        "let pointsTensor: Tensor = new Tensor(\"float32\", points, [1, 1, 1, 2]);\n",
        "let labelsTensor: Tensor = new Tensor(\"float32\", labels, [1,1,labels.length]);\n",
        "let originalSize: Tensor = new Tensor(\"int64\", [dims[1], dims[0]], [2]);\n",
        "const [mask, decoderTime] = await runDecoder(decoderSession, embedding, pointsTensor, labelsTensor, originalSize);\n",
        "var decoderOutput = mask.data;\n",
        "var inferenceTime = decoderTime;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "function transposeChannel(data, dims) {\n",
        "    let transposedData = new Float32Array(dims[3]*dims[4]*dims[2]);\n",
        "    const channelLength = dims[3]*dims[4];\n",
        "    for (let i = 0; i < data.length; i+=3) {\n",
        "        transposedData[i] = data[i];\n",
        "        transposedData[i+1] = data[i+channelLength];\n",
        "        transposedData[i+2] = data[i+2*channelLength];\n",
        "    }\n",
        "    return transposedData;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 59,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[ 256, 207 ]\n"
          ]
        }
      ],
      "source": [
        "let a = [0,2,4,5]\n",
        "mask.dims.slice(3,)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {},
      "outputs": [],
      "source": [
        "// let transposedMask = imageDataToTensor(decoderOutput, mask.dims.slice(2,), 1);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {},
      "outputs": [],
      "source": [
        "let maskImage = new Uint8Array(dims[0]*dims[1]);\n",
        "let decoderOutputSlice = (decoderOutput as Float32Array).slice(0,dims[0]*dims[1]);\n",
        "for (let i=0; i<decoderOutputSlice.length; i++) {\n",
        "    if (decoderOutputSlice[i] >= 0) {\n",
        "        maskImage[i] = 1;\n",
        "        // maskImage[i+1] = 1;\n",
        "        // maskImage[i+2] = 1;\n",
        "    } else {\n",
        "        maskImage[i] = 0;\n",
        "        // maskImage[i+1] = 0;\n",
        "        // maskImage[i+2] = 0;\n",
        "    }\n",
        "}\n",
        "// let transposedMask = transposeChannel(maskImage, mask.dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Float32Array(52992) [\n",
            "  -3.8637492656707764,  -3.991184711456299,  -3.871520757675171,\n",
            "  -3.9694225788116455, -3.9836342334747314,  -4.037299633026123,\n",
            "  -3.7964789867401123, -3.8899168968200684,  -4.081902503967285,\n",
            "  -3.6294565200805664, -3.7999801635742188, -3.9474992752075195,\n",
            "  -3.5137012004852295, -3.7479207515716553,  -3.833216667175293,\n",
            "  -3.6118245124816895, -3.6930220127105713, -3.7316269874572754,\n",
            "  -3.7313129901885986,  -3.580113172531128,  -3.673612117767334,\n",
            "    -3.85579514503479,  -3.466813564300537,  -3.650151014328003,\n",
            "  -3.8262174129486084, -3.3521599769592285, -3.6383109092712402,\n",
            "   -3.736264228820801, -3.4498677253723145, -3.6410231590270996,\n",
            "   -3.667262077331543, -3.5994133949279785, -3.5492658615112305,\n",
            "  -3.6287851333618164, -3.7613775730133057,  -3.454685688018799,\n",
            "  -3.6444153785705566,  -3.826319932937622,  -3.360084056854248,\n",
            "  -3.6582911014556885, -3.7635347843170166,  -3.414520263671875,\n",
            "  -3.6786434650421143, -3.7053258419036865,   -3.56730318069458,\n",
            "   -3.608478546142578, -3.6527912616729736, -3.7245798110961914,\n",
            "  -3.5067272186279297, -3.6723837852478027, -3.8524274826049805,\n",
            "   -3.402068614959717,  -3.691086530685425,  -3.798336982727051,\n",
            "  -3.3872854709625244,  -3.710322856903076,  -3.742814540863037,\n",
            "  -3.5470948219299316, -3.6729531288146973,  -3.691819667816162,\n",
            "   -3.693002223968506, -3.5727410316467285, -3.7155802249908447,\n",
            "   -3.883150815963745, -3.4818592071533203,  -3.753519058227539,\n",
            "    -3.87463116645813, -3.4209446907043457, -3.8362865447998047,\n",
            "  -3.8579695224761963, -3.5933637619018555, -3.7963998317718506,\n",
            "    -3.75874400138855,   -3.65401029586792, -3.5710113048553467,\n",
            "  -3.6027746200561523, -3.6681110858917236,  -3.311378002166748,\n",
            "    -3.43135404586792, -3.5250864028930664,  -3.024148464202881,\n",
            "   -3.295924425125122,  -3.334453821182251, -3.0126986503601074,\n",
            "   -3.283762216567993, -3.2186050415039062,  -3.186533212661743,\n",
            "  -3.2550511360168457,  -3.267383098602295, -3.4715030193328857,\n",
            "  -3.2529373168945312, -3.4862453937530518,  -3.717782735824585,\n",
            "   -3.282818078994751, -3.6000266075134277,  -3.693619966506958,\n",
            "  -3.3815431594848633,  -3.643192768096924, -3.6767964363098145,\n",
            "   -3.567213535308838,\n",
            "  ... 52892 more items\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "decoderOutputSlice"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "158976\n"
          ]
        }
      ],
      "source": [
        "maskImage.reduce((a,b) => a+b, 0)\n",
        "// getMax(maskImage)\n",
        "\n",
        "maskImage.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {},
      "outputs": [],
      "source": [
        "let stack_mask = stackSliceToRGB(maskImage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uint8Array(10) [\n",
            "  0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0\n",
            "]\n",
            "Mat {}\n"
          ]
        }
      ],
      "source": [
        "imagedataToImage((stack_mask), [dims[0], dims[1]]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1811852.2913827675\n"
          ]
        }
      ],
      "source": [
        "function sigmoid(data) {\n",
        "    return data.map(x => 1 / (1 + Math.exp(-x)))\n",
        "}\n",
        "\n",
        "function softmax(data) { \n",
        "    return data.map(x => Math.exp(x) / (data.map(y => Math.exp(y))).reduce((a,b) => a+b)) \n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "typescript",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
