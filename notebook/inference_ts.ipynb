{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "**Creating a 3D array of size (2, 9, 5)**\n",
        "```python\n",
        "array_3d = np.array([\n",
        "    [\n",
        "        [1, 2, 3, 4, 5],\n",
        "        [6, 7, 8, 9, 10],\n",
        "        [41, 42, 43, 44, 45]\n",
        "    ],\n",
        "    [\n",
        "        [46, 47, 48, 49, 50],\n",
        "        [81, 82, 83, 84, 85],\n",
        "        [86, 87, 88, 89, 90]\n",
        "    ]\n",
        "])\n",
        "```\n",
        "\n",
        "**Get flatten array from index [:,:,1]**\n",
        "```python\n",
        "array_3d[:,:,1].flatten() \n",
        "```\n",
        "\n",
        "[ 2  7 42 47 82 87]\n",
        "\n",
        "=**Get flatten array from index [:,1,:]**\n",
        "```python\n",
        "array_3d[:,1,:].flatten()\n",
        "```\n",
        "\n",
        "[ 6  7  8  9 10 81 82 83 84 85]\n",
        "\n",
        "**Get flatten array from index [1,:,:]**\n",
        "```python\n",
        "array_3d[1,:,:].flatten()\n",
        "```\n",
        "\n",
        "[46 47 48 49 50 81 82 83 84 85 86 87 88 89 90]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "import {InferenceSession, Tensor, env} from 'onnxruntime-web';\n",
        "const ndarray = require('ndarray')\n",
        "const ops = require('ndarray-ops')\n",
        "const fs = require('fs')\n",
        "import Jimp from \"jimp\";\n",
        "import { Niivue, NVImage } from \"@niivue/niivue\";\n",
        "import { cv } from \"opencv-wasm\";\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Uint8Array(11393280) [\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
            "  0, 0, 0, 0,\n",
            "  ... 11393180 more items\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "// in kernel, The configuration runs using node, and not in the browser,\n",
        "// which is why window is not defined\n",
        "// we need to define it to make the code work\n",
        "\n",
        "// global.window = { navigator: { userAgent: 'node.js' } };\n",
        "\n",
        "import crypto from \"node:crypto\";\n",
        "global.crypto ??= crypto;\n",
        "const volume = await NVImage.loadFromUrl({url:\"https://niivue.github.io/niivue-demo-images/mni152.nii.gz\"})\n",
        "console.log(volume.img)\n",
        "\n",
        "// import fs from 'fs';\n",
        "\n",
        "// const writeStream = fs.createWriteStream('file.txt');\n",
        "// const pathName = writeStream.path;\n",
        "  \n",
        "// // write each value of the array on the file breaking line\n",
        "// volume.img.forEach(value => writeStream.write(`${value}\\n`));\n",
        "\n",
        "// // the finish event is emitted when all data has been flushed from the stream\n",
        "// writeStream.on('finish', () => {\n",
        "//    console.log(`wrote all the array data to file ${pathName}`);\n",
        "// });\n",
        "\n",
        "// // handle the errors on the write process\n",
        "// writeStream.on('error', (err) => {\n",
        "//     console.error(`There is an error writing the file ${pathName} => ${err}`)\n",
        "// });\n",
        "\n",
        "// // close the stream\n",
        "// writeStream.end();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [],
      "source": [
        "function getMax(arr) {\n",
        "    let len = arr.length;\n",
        "    let max = -Infinity;\n",
        "\n",
        "    while (len--) {\n",
        "        max = arr[len] > max ? arr[len] : max;\n",
        "    }\n",
        "    return max;\n",
        "}\n",
        "\n",
        "function getMin(arr) {\n",
        "    let len = arr.length;\n",
        "    let min = Infinity;\n",
        "\n",
        "    while (len--) {\n",
        "        min = arr[len] < min ? arr[len] : min;\n",
        "    }\n",
        "    return min;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "function normalizeArray(\n",
        "    array: Float32Array | Uint8Array,\n",
        "    max: number\n",
        "  ): Float32Array {\n",
        "    let normalizedArray = new Float32Array(array.length);\n",
        "    for (let i = 0; i < array.length; i++) {\n",
        "      normalizedArray[i] = array[i] / max;\n",
        "    }\n",
        "    return normalizedArray;\n",
        "  }\n",
        "  \n",
        "  function stackSliceToRGB(\n",
        "    buffer: Float32Array | Uint8Array,\n",
        "  ): Float32Array {\n",
        "    let bufferLength = buffer.length,\n",
        "      result = new Float32Array(bufferLength * 3);\n",
        "  \n",
        "    for (let i = 0; i < bufferLength; i++) {\n",
        "      result[3 * i] = buffer[i];\n",
        "      result[3 * i + 1] = buffer[i];\n",
        "      result[3 * i + 2] = buffer[i];\n",
        "    }\n",
        "    return result;\n",
        "  }\n",
        "  \n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "5:36 - Cannot find name 'inputImage'.\n",
            "6:31 - Cannot find name 'inputImage'.\n",
            "6:56 - Cannot find name 'inputImage'.\n"
          ]
        }
      ],
      "source": [
        "const resize = async () => {\n",
        "    // let jimpSrc = await Jimp.read('/data/Projects/deepsyence/notebook/niivue.png');\n",
        "\n",
        "    // var src = cv.matFromImageData(jimpSrc.bitmap);\n",
        "    var image4channel = addChannel(inputImage.data);\n",
        "    var src = cv.matFromArray(inputImage.size().width, inputImage.size().height, cv.CV_8UC4, image4channel);\n",
        "    console.log(src.size(), src.type(), src.data);\n",
        "    let dst = new cv.Mat();\n",
        "    cv.resize(src, dst, { width: 100, height: 100 }, cv.INTER_CUBIC);\n",
        "    console.log(dst.size(), dst.type(), dst.data);\n",
        "    new Jimp({\n",
        "        width: dst.cols,\n",
        "        height: dst.rows,\n",
        "        data: Buffer.from(dst.data)\n",
        "    })\n",
        "        .write('/data/Projects/deepsyence/notebook/niivue_resize.png');\n",
        "}\n",
        "resize();"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "const preprocessVolume = (image) => {\n",
        "    try {\n",
        "      const imageRAS = image.img2RAS();\n",
        "      // console.log(\"image.calMax, image.calMin \", image.global_max, image.global_min);\n",
        "      const maxVal = getMax(imageRAS);\n",
        "      const normalizedArray = normalizeArray(imageRAS, maxVal);\n",
        "      console.log(\"normalizedArray \", maxVal, normalizedArray.reduce((a, b) => a + b, 0));\n",
        "      return normalizedArray;\n",
        "    } catch (e) {\n",
        "      console.log(`failed to preprocess volume: ${e}. `);\n",
        "      throw Error(`failed to preprocess volume: ${e}. `);\n",
        "    }\n",
        "  }\n",
        "\n",
        "const preprocess = (slice2D: Float32Array, sliceId: number, width: number, height: number): Float32Array => {\n",
        "    try {\n",
        "      // console.log(\"imageArray \", slice2D);\n",
        "      let image3Channels: Float32Array;\n",
        "      const sliceArray = slice2D.slice(\n",
        "        width * height * sliceId,\n",
        "        width * height * (sliceId + 1),\n",
        "      );\n",
        "      console.log(\"sliceArray \", sliceArray.reduce((a, b) => a + b, 0));\n",
        "  \n",
        "      image3Channels = stackSliceToRGB(sliceArray);\n",
        "      console.log(\"image3Channels \", image3Channels, image3Channels.reduce((a, b) => a + b, 0));\n",
        "      return image3Channels;\n",
        "    } catch (e) {\n",
        "      console.log(`failed to inference ONNX model: ${e}. `);\n",
        "      throw Error(`failed to inference ONNX model: ${e}. `);\n",
        "    }\n",
        "};\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "function addChannel(buffer: Float32Array | Uint8Array): Uint8Array {\n",
        "  let bufferLength = buffer.length,\n",
        "    result = new Uint8Array((bufferLength / 3) * 4);\n",
        "\n",
        "  for (let i = 0; i < bufferLength; i += 3) {\n",
        "    result[(4 * i) / 3] = buffer[i] * 1;\n",
        "    result[(4 * i) / 3 + 1] = buffer[i + 1] * 1;\n",
        "    result[(4 * i) / 3 + 2] = buffer[i + 2] * 1;\n",
        "    result[(4 * i) / 3 + 3] = 255;\n",
        "  }\n",
        "  return result;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "function resizeLongesSide (image: any, target_length: number) {\n",
        "    let dstResized = new cv.Mat();\n",
        "    let image4Channels;\n",
        "    let oldw = image.size().width\n",
        "    let oldh = image.size().height\n",
        "    console.log(\"oldh, oldw \", oldh, oldw, image.size());\n",
        "    let scale = target_length * 1.0 / Math.max(oldh, oldw)\n",
        "    let newh = oldh * scale\n",
        "    let neww = oldw * scale\n",
        "    console.log(\"target_size \", newh, neww, new cv.Size(newh, neww));\n",
        "    if (image.type() !== cv.CV_8UC4) {\n",
        "        image4Channels = addChannel(image.data);\n",
        "    }\n",
        "    var src = cv.matFromArray(oldw, oldh, cv.CV_8UC4, image4Channels);\n",
        "    \n",
        "    cv.resize(src, dstResized, new cv.Size(newh, neww), 0, 0, cv.INTER_CUBIC);\n",
        "    console.log(\"dstResized \", dstResized.size(), dstResized.type());\n",
        "    new Jimp({\n",
        "        width: dstResized.cols,\n",
        "        height: dstResized.rows,\n",
        "        data: Buffer.from(dstResized.data)\n",
        "    })\n",
        "        .write('/data/Projects/deepsyence/notebook/niivue_resize_1.png');\n",
        "    return dstResized;\n",
        "}\n",
        "\n",
        "function pad(image: any, target_size: number) {\n",
        "    let dstPadded = new cv.Mat();\n",
        "    let image4Channels;\n",
        "    let h = image.size().height\n",
        "    let w = image.size().width\n",
        "    let padh = target_size - h\n",
        "    let padw = target_size - w\n",
        "    console.log(\"padh, padw \", padh, padw);\n",
        "    if (image.type() !== cv.CV_8UC4) {\n",
        "        image4Channels = addChannel(image.data);\n",
        "    }\n",
        "    //  copyMakeBorder( src, dst, top, bottom, left, right, borderType, value );\n",
        "    cv.copyMakeBorder(image, dstPadded, 0, padh, 0, padw, cv.BORDER_CONSTANT);\n",
        "    new Jimp({\n",
        "        width: dstPadded.cols,\n",
        "        height: dstPadded.rows,\n",
        "        data: Buffer.from(dstPadded.data)\n",
        "    })\n",
        "        .write('/data/Projects/deepsyence/notebook/niivue_padded.png');\n",
        "    return dstPadded;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "function imagedataToImage(imagedata: Float32Array | Uint8Array, dims: number[]) {\n",
        "    let inputImage;\n",
        "    // if (dims[0]*dims[1] !== imagedata.length) {\n",
        "    //     throw new Error(\"Image data size does not match the dimensions\");\n",
        "    // }\n",
        "\n",
        "      inputImage = new Uint8Array(dims[0]*dims[1]*3);\n",
        "      for (let i=0; i<imagedata.length; i++) {\n",
        "        inputImage[i] = imagedata[i]*255;\n",
        "    }\n",
        "\n",
        "    let dst = cv.matFromArray(dims[0], dims[1], cv.CV_8UC3, inputImage);\n",
        "\n",
        "    // console.inputTensor.dims[3log(dst.data.slice(600, 610));\n",
        "    // console.log(dst);\n",
        "    new Jimp({\n",
        "        width: dims[0],\n",
        "        height: dims[1],\n",
        "        data: Buffer.from(dst.data)\n",
        "    }).write('./niivue.png');\n",
        "    return dst;\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [],
      "source": [
        "function nvVolumetoSlice(volume, dims, fov, index): any {\n",
        "    let sliceArray;\n",
        "    switch (fov) {\n",
        "        // sagittal dimsRAS[1], coronal dimsRAS[2], axial dimsRAS[3]\n",
        "        \n",
        "        // 1. if axial, slice the array from volume\n",
        "        case \"axial\":\n",
        "            sliceArray = volume.slice(\n",
        "                dims[0] * dims[1] * index,\n",
        "                dims[0] * dims[1] * (index + 1),\n",
        "            );\n",
        "            console.log(\"axial sliceArray\",dims[1], dims[2], index, sliceArray.length);\n",
        "        // 2. if coronal, \n",
        "        case \"coronal\":\n",
        "        // 3. if sagittal,\n",
        "        case \"sagittal\":\n",
        "    }\n",
        "    return sliceArray;\n",
        "    \n",
        "}\n",
        "\n",
        "function filterAlphaChannel(\n",
        "    image: Array<number>,\n",
        "): Float32Array {\n",
        "    // 4. convert to float32\n",
        "    let i,\n",
        "      l = image.length; // length, we need this for the loop\n",
        "    console.log(\"image.length\", image.length);\n",
        "    // create the Float32Array size 3 * 224 * 224 for these dimensions output\n",
        "    const float32Data = new Float32Array((image.length * 3) / 4);\n",
        "    for (i = 0; i < l; i += 4) {\n",
        "      float32Data[(3 * i) / 4] = image[i]; // convert to float\n",
        "      float32Data[(3 * i) / 4 + 1] = image[i + 1]; // convert to float\n",
        "      float32Data[(3 * i) / 4 + 2] = image[i + 2]; // convert to float\n",
        "      // skip image[i + 3] to filter out the alpha channel\n",
        "    }\n",
        "    // console.log(\"float32Data\", float32Data)\n",
        "    return float32Data;\n",
        "}\n",
        "\n",
        "function nvSliceToTensor(nvSlice, dims): any {\n",
        "    console.log(\"nvSlice\", nvSlice.length);\n",
        "    // 1. preprocess\n",
        "    let image3Channels = stackSliceToRGB(nvSlice);\n",
        "    // 2. convert to float32\n",
        "    console.log(\"image3Channels\", image3Channels.length);\n",
        "    // 3. tensor\n",
        "    const inputTensor = new Tensor(\"float32\", image3Channels, dims);\n",
        "    return inputTensor;\n",
        "}\n",
        "\n",
        "function imageDataToTensor(data, dims, max): any {\n",
        "    // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
        "    const [R, G, B]: number[][] = [[], [], []];\n",
        "    const channels = (data.length / (dims[3]*dims[2]*3)) % 4 ? 3 : 4;\n",
        "    console.log(\"channels\", data.length, channels);\n",
        "    for (let i = 0; i < data.length; i += channels) {\n",
        "      R.push(data[i]);\n",
        "      G.push(data[i + 1]);\n",
        "      B.push(data[i + 2]);\n",
        "      // 2. skip data[i + 3] thus filtering out the alpha channel\n",
        "    }\n",
        "    // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
        "    const transposedData = R.concat(G).concat(B);\n",
        "  \n",
        "    // 3. convert to float32\n",
        "    let i, l = transposedData.length; // length, we need this for the loop\n",
        "    const float32Data = new Float32Array(dims[3]*dims[1]*dims[2]); // create the Float32Array for output\n",
        "    for (i = 0; i < l; i++) {\n",
        "      float32Data[i] = transposedData[i] ; // divide by max value to convert to float\n",
        "    }\n",
        "  \n",
        "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
        "    return inputTensor;\n",
        "  }\n",
        "\n",
        "function arrayToTensor(array, dims): any {\n",
        "    let float32Data = new Float32Array(array.length*3);\n",
        "    for (let i = 0; i < array.length; i++) {\n",
        "        float32Data[i] = array[i];\n",
        "        float32Data[i + array.length] = array[i];\n",
        "        float32Data[i + 2 * array.length] = array[i];\n",
        "    }\n",
        "    const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
        "    return inputTensor;\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizedArray  252 3269611.783972291\n",
            "axial sliceArray 256 215 90 52992\n",
            "nvSlice 52992\n",
            "image3Channels 158976\n",
            "oldh, oldw  207 256 { width: 256, height: 207 }\n",
            "target_size  207 256 Size { width: 207, height: 256 }\n",
            "dstResized  { width: 207, height: 256 } 24\n",
            "padh, padw  0 49\n",
            "image.length 262144\n",
            "paddedImage  { width: 256, height: 256 } 24 Uint8Array(262144) [\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255, 0, 0, 0, 255, 0, 0, 0, 255,\n",
            "  0, 0, 0, 255,\n",
            "  ... 262044 more items\n",
            "]\n",
            "channels 196608 3\n"
          ]
        }
      ],
      "source": [
        "// LiteMedSAM\n",
        "const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
        "let nvVolume = preprocessVolume(volume);\n",
        "let nvSlice = nvVolumetoSlice(nvVolume, dims, \"axial\", 90);\n",
        "let inputTensor = nvSliceToTensor(nvSlice, [1, 3, dims[0], dims[1]]);\n",
        "\n",
        "let inputImage = imagedataToImage(inputTensor.data, [dims[0], dims[1]]);\n",
        "let resizedImage = resizeLongesSide(inputImage, 256);\n",
        "let paddedImage = pad(resizedImage, 256);\n",
        "let filteredImage = filterAlphaChannel(paddedImage.data);\n",
        "console.log(\"paddedImage \", paddedImage.size(), paddedImage.type(), paddedImage.data);\n",
        "const maxVal = getMax(filteredImage);\n",
        "let normalizedImage = normalizeArray(filteredImage, maxVal);\n",
        "// let stackImage = stackSliceToRGB(normalizedImage);\n",
        "let transposedTensor = imageDataToTensor(normalizedImage, [1, 3, paddedImage.size().width, paddedImage.size().height], maxVal);\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1\n"
          ]
        }
      ],
      "source": [
        "getMax(transposedTensor.data);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "33123738\n"
          ]
        }
      ],
      "source": [
        "transposedTensor.data.reduce((a, b) => a + b, 0);\n",
        "paddedImage.data.reduce((a, b) => a + b, 0);\n",
        "resizedImage.data.reduce((a, b) => a + b, 0);\n",
        "// inputImage.data.reduce((a, b) => a + b, 0);\n",
        "// nvSlice.reduce((a, b) => a + b, 0);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Jimp {\n",
            "  _events: [Object: null prototype] {},\n",
            "  _eventsCount: 0,\n",
            "  _maxListeners: undefined,\n",
            "  bitmap: {\n",
            "    data: <Buffer 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 00 ff 00 00 ... 211918 more bytes>,\n",
            "    width: 207,\n",
            "    height: 256\n",
            "  },\n",
            "  _background: 0,\n",
            "  _originalMime: 'image/png',\n",
            "  _exif: null,\n",
            "  _rgba: true,\n",
            "  writeAsync: [Function (anonymous)],\n",
            "  getBase64Async: [Function (anonymous)],\n",
            "  getBuffer: [Function: getBuffer],\n",
            "  getBufferAsync: [Function: getBufferAsync],\n",
            "  getPixelColour: [Function: getPixelColor],\n",
            "  setPixelColour: [Function: setPixelColor],\n",
            "  [Symbol(kCapture)]: false\n",
            "}\n"
          ]
        }
      ],
      "source": [
        "new Jimp({\n",
        "    width: resizedImage.cols,\n",
        "    height: resizedImage.rows,\n",
        "    data: Buffer.from(resizedImage.data)\n",
        "}).write('./padded.png');"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "normalizedArray  3269611.783972291\n",
            "axial sliceArray 256 215 90 52992\n",
            "nvSlice 52992\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "image3Channels 158976\n"
          ]
        }
      ],
      "source": [
        "// EfficientSAM\n",
        "const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
        "let nvVolume = preprocessVolume(volume);\n",
        "let nvSlice = nvVolumetoSlice(nvVolume, dims, \"axial\", 90);\n",
        "let inputTensor = nvSliceToTensor(nvSlice, [1, 3, dims[0], dims[1]]);\n",
        "const maxVal = getMax(volume.img2RAS());\n",
        "let transposedTensor = imageDataToTensor(inputTensor.data, [1, 3, dims[1], dims[0]], maxVal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Float32Array(7) [\n",
            "  0.4246031641960144,\n",
            "  0.4246031641960144,\n",
            "  0.2936508059501648,\n",
            "  0.2936508059501648,\n",
            "  0.2936508059501648,\n",
            "  0.1626984179019928,\n",
            "  0.1626984179019928\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "inputTensor.data.slice(16000,16007)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "axial sliceArray 256 215 90 52992\n"
          ]
        }
      ],
      "source": [
        "// const dims = [volume.dimsRAS[1], volume.dimsRAS[2], volume.dimsRAS[3]];\n",
        "// // let nvVolume = preprocessVolume(volume);\n",
        "// let nvSlice = nvVolumetoSlice(volume.img2RAS(), dims, \"axial\", 90);\n",
        "// // let inputImage = nvSliceToImage(nvSlice);\n",
        "// const maxVal = getMax(volume.img2RAS());\n",
        "// let inputTensor = arrayToTensor(nvSlice, [1, 3, dims[0], dims[1]], maxVal);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mat {}\n"
          ]
        }
      ],
      "source": [
        "imagedataToImage(inputTensor.data, [dims[0], dims[1]]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77127.94049503142 [ 1, 3, 256, 207 ] 0.932539701461792 0\n",
            "823942169 252 0 80 40\n"
          ]
        }
      ],
      "source": [
        "console.log(transposedTensor.data.reduce((a,b) => a+b,0), transposedTensor.dims, getMax(transposedTensor.data), getMin(transposedTensor.data));\n",
        "\n",
        "console.log(volume.img2RAS().reduce((a,b) => a+b, 0), getMax(volume.img), getMin(volume.img), volume.global_max, volume.global_min);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "77127.94049503142 [ 1, 3, 256, 207 ] 0.932539701461792 0\n",
            "823942169 252 0 80 40\n"
          ]
        }
      ],
      "source": [
        "console.log(inputTensor.data.reduce((a,b) => a+b,0), inputTensor.dims, getMax(inputTensor.data), getMin(inputTensor.data));\n",
        "\n",
        "console.log(volume.img2RAS().reduce((a,b) => a+b, 0), getMax(volume.img), getMin(volume.img), volume.global_max, volume.global_min);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [],
      "source": [
        "global.self = global;\n",
        "env.wasm.numThreads = 1;\n",
        "\n",
        "// LiteMedSAM\n",
        "const encoderSession = await InferenceSession.create('../public/model/lite_medsam_encoder_optimized.onnx');\n",
        "const decoderSession = await InferenceSession.create('../public/model/litemedsam_decoder_nomaskinput.opt.onnx');\n",
        "\n",
        "// Efficient SAM\n",
        "// const encoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_encoder.onnx');\n",
        "// const decoderSession = await InferenceSession.create('../public/model/efficient_sam_vitt_decoder.onnx');\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "async function runEncoder(model, preprocessedData): Promise<[Tensor, number]> {\n",
        "    const start = new Date();\n",
        "    try {\n",
        "      const feeds: Record<string, Tensor> = {};\n",
        "      feeds[model.inputNames[0]] = preprocessedData;\n",
        "      const outputData = await model.run(feeds);\n",
        "      const end = new Date();\n",
        "      const inferenceTime = (end.getTime() - start.getTime());\n",
        "      const output = outputData[model.outputNames[0]];\n",
        "      return [output, inferenceTime];\n",
        "    } catch (e) {\n",
        "      console.error(e);\n",
        "      throw new Error();\n",
        "    }\n",
        "  }\n",
        "\n",
        "async function runDecoder(model, embedding, inputPoints, inputLabels, oriSize): Promise<[Tensor, number]> {\n",
        "  const decoderStart = new Date();\n",
        "  try {\n",
        "    const decoderFeeds: Record<string, Tensor> = {};\n",
        "    console.log(\"model.inputNames\", model.inputNames)\n",
        "\n",
        "    const maskInput = new Tensor(\n",
        "      \"float32\",\n",
        "      new Float32Array(256 * 256),\n",
        "      [1, 1, 256, 256]\n",
        "    );\n",
        "    // There is no previous mask, so default to 0\n",
        "    const hasMaskInput = new Tensor(\"float32\", [0]);\n",
        "\n",
        "    decoderFeeds[model.inputNames[0]] = embedding;\n",
        "    decoderFeeds[model.inputNames[1]] = inputPoints;\n",
        "    decoderFeeds[model.inputNames[2]] = inputLabels;\n",
        "    // decoderFeeds[model.inputNames[3]] = maskInput;\n",
        "    // decoderFeeds[model.inputNames[4]] = hasMaskInput;\n",
        "    decoderFeeds[model.inputNames[3]] = oriSize;\n",
        "\n",
        "    // feeds[model.inputNames[1]] = new Tensor(\"float32\", inputPoints, [1, 1, inputPoints.length/2, 2]);\n",
        "    // feeds[model.inputNames[2]] = new Tensor(\"float32\", new Array(inputPoints.length/2).fill(1), inputPoints.length/2);\n",
        "    // feeds[model.inputNames[3]] = new Tensor(\"int64\", oriSize);\n",
        "    const outputData = await model.run(decoderFeeds);\n",
        "    const decoderEnd = new Date();\n",
        "    const decoderInferenceTime = (decoderEnd.getTime() - decoderStart.getTime());\n",
        "    const decoderOutput = outputData[model.outputNames[0]];\n",
        "    return [decoderOutput, decoderInferenceTime];\n",
        "  } catch (e) {\n",
        "    console.error(e);\n",
        "    throw new Error();\n",
        "  }\n",
        "}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "const [embedding, encoderTime] =  await runEncoder(encoderSession, transposedTensor);\n",
        "var encoderOutput = embedding.data;\n",
        "var inferenceTime = encoderTime;\n",
        "// var results = softmax(Array.prototype.slice.call(output))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 131,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-2369.545148893376 11578 0.7205691337585449 -0.9109674096107483\n"
          ]
        }
      ],
      "source": [
        "console.log((encoderOutput as Float32Array).reduce((a,b) => a + b, 0), inferenceTime, getMax(encoderOutput), getMin(encoderOutput));"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "const scale = 256 / Math.max(dims[0], dims[1]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "model.inputNames [\n",
            "  'image_embeddings',\n",
            "  'batched_point_coords',\n",
            "  'batched_point_labels',\n",
            "  'orig_im_size'\n",
            "]\n"
          ]
        }
      ],
      "source": [
        "let points = new Float32Array([134*scale, 150*scale])\n",
        "let labels = new Float32Array(points.length/2).fill(1)\n",
        "let boxTensor: Tensor = new Tensor(\"float32\", new Float32Array([0,0,205,254]), [1, 2, 2]);\n",
        "// let pointsTensor: Tensor = new Tensor(\"float32\", points, [1, 1, 2]);\n",
        "let labelsTensor: Tensor = new Tensor(\"float32\", new Float32Array([2,3]), [1,2]);\n",
        "let originalSize: Tensor = new Tensor(\"int64\", [dims[1], dims[0]], [2]);\n",
        "const [mask, decoderTime] = await runDecoder(decoderSession, embedding, boxTensor, labelsTensor, originalSize);\n",
        "var decoderOutput = mask.data;\n",
        "var inferenceTime = decoderTime;"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "let maskImage = new Uint8Array(dims[0]*dims[1]);\n",
        "let decoderOutputSlice = (decoderOutput as Float32Array).slice(0,dims[0]*dims[1]);\n",
        "for (let i=0; i<decoderOutputSlice.length; i++) {\n",
        "    if (decoderOutputSlice[i] >= 0) {\n",
        "        maskImage[i] = 1;\n",
        "        // maskImage[i+1] = 1;\n",
        "        // maskImage[i+2] = 1;\n",
        "    } else {\n",
        "        maskImage[i] = 0;\n",
        "        // maskImage[i+1] = 0;\n",
        "        // maskImage[i+2] = 0;\n",
        "    }\n",
        "}\n",
        "// let transposedMask = transposeChannel(maskImage, mask.dims)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "52992\n"
          ]
        }
      ],
      "source": [
        "decoderOutput.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "24473\n"
          ]
        }
      ],
      "source": [
        "maskImage.reduce((a,b) => a+b, 0)\n",
        "// getMax(maskImage)\n",
        "\n",
        "// maskImage.length"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "let stack_mask = stackSliceToRGB(maskImage)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mat {}\n"
          ]
        }
      ],
      "source": [
        "imagedataToImage((stack_mask), [dims[0], dims[1]]);"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-1811852.2913827675\n"
          ]
        }
      ],
      "source": [
        "function sigmoid(data) {\n",
        "    return data.map(x => 1 / (1 + Math.exp(-x)))\n",
        "}\n",
        "\n",
        "function softmax(data) { \n",
        "    return data.map(x => Math.exp(x) / (data.map(y => Math.exp(y))).reduce((a,b) => a+b)) \n",
        "}\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "TypeScript",
      "language": "typescript",
      "name": "tslab"
    },
    "language_info": {
      "codemirror_mode": {
        "mode": "typescript",
        "name": "javascript",
        "typescript": true
      },
      "file_extension": ".ts",
      "mimetype": "text/typescript",
      "name": "typescript",
      "version": "3.7.2"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
