{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import {InferenceSession, Tensor} from 'onnxruntime-node';\n",
    "const ndarray = require('ndarray')\n",
    "const ops = require('ndarray-ops')\n",
    "const fs = require('fs')\n",
    "const bisweb = require('biswebnode')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32Array(10587136) [\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1,\n",
      "  ... 10587036 more items\n",
      "]\n",
      "input_1\n",
      "data of result tensor 'c': [object Object]\n",
      "{\n",
      "  conv2d_transpose_4: l {\n",
      "    dims: [ 211, 224, 224, 1 ],\n",
      "    type: 'float32',\n",
      "    data: Float32Array(10587136) [\n",
      "      0.002875823061913252,\n",
      "      -0.0035482447128742933,\n",
      "      0.0015134376008063555,\n",
      "      -0.00024906962062232196,\n",
      "      -0.0005567597690969706,\n",
      "      -0.0010869965190067887,\n",
      "      0.0001240931887878105,\n",
      "      0.00011437403009040281,\n",
      "      -0.00022227723093237728,\n",
      "      0.0006404236191883683,\n",
      "      0.00023755755682941526,\n",
      "      0.00027328336727805436,\n",
      "      0.0003408203483559191,\n",
      "      0.0003292314358986914,\n",
      "      -0.000867693976033479,\n",
      "      -0.000025216719222953543,\n",
      "      -0.00026807174435816705,\n",
      "      0.000623763888143003,\n",
      "      0.0004807364020962268,\n",
      "      0.00021195053705014288,\n",
      "      0.000463163509266451,\n",
      "      0.0006921188905835152,\n",
      "      -0.0005973390652798116,\n",
      "      -0.000010205082617176231,\n",
      "      -0.0005040581454522908,\n",
      "      0.0007603944977745414,\n",
      "      0.00030902118305675685,\n",
      "      0.0002571728837210685,\n",
      "      0.0002412117028143257,\n",
      "      0.0006016475963406265,\n",
      "      -0.0006641682703047991,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      0.0004117638454772532,\n",
      "      0.0006144867511466146,\n",
      "      -0.0006235971814021468,\n",
      "      -0.000012708710528386291,\n",
      "      -0.00023926781432237476,\n",
      "      0.0007482169312424958,\n",
      "      0.00014902283146511763,\n",
      "      0.0002887848822865635,\n",
      "      0.0001842194324126467,\n",
      "      0.0003481882740743458,\n",
      "      -0.0007447589887306094,\n",
      "      0.000041315735870739445,\n",
      "      -0.00006177217437652871,\n",
      "      0.0006873163511045277,\n",
      "      0.00043464923510327935,\n",
      "      0.0002117853582603857,\n",
      "      0.00045981729635968804,\n",
      "      0.0005580204888246953,\n",
      "      -0.0005699909524992108,\n",
      "      0.0000015971015727700433,\n",
      "      -0.00028677735826931894,\n",
      "      0.000701667508110404,\n",
      "      0.0002965375024359673,\n",
      "      0.0002098641562042758,\n",
      "      0.0002538953849580139,\n",
      "      0.0005345850950106978,\n",
      "      -0.0007433714345097542,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      0.0004117638454772532,\n",
      "      0.0006144867511466146,\n",
      "      -0.0006235971814021468,\n",
      "      -0.000012708710528386291,\n",
      "      -0.00023926781432237476,\n",
      "      0.0007482169312424958,\n",
      "      0.00014902283146511763,\n",
      "      0.0002887848822865635,\n",
      "      0.0001842194324126467,\n",
      "      0.0003481882740743458,\n",
      "      -0.0007447589887306094,\n",
      "      0.000041315735870739445,\n",
      "      -0.00006177217437652871,\n",
      "      0.0006873163511045277,\n",
      "      0.00043464923510327935,\n",
      "      0.0002117853582603857,\n",
      "      0.00045981729635968804,\n",
      "      0.0005580204888246953,\n",
      "      -0.0005699909524992108,\n",
      "      0.0000015971015727700433,\n",
      "      -0.00028677735826931894,\n",
      "      0.000701667508110404,\n",
      "      0.0002965375024359673,\n",
      "      0.0002098641562042758,\n",
      "      0.0002538953849580139,\n",
      "      0.0005345850950106978,\n",
      "      -0.0007433714345097542,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      ... 10587036 more items\n",
      "    ],\n",
      "    size: 10587136\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import {InferenceSession, Tensor, env} from 'onnxruntime-web';\n",
    "const fs = require('fs')\n",
    "\n",
    "\n",
    "// use an async context to call onnxruntime functions.\n",
    "async function main() {\n",
    "    try {\n",
    "\n",
    "        // const float32Data = new Float32Array(160*256*256*1).fill(1);\n",
    "        // const inputTensor = new Tensor(\"float32\", float32Data, [160,256,256,1]);\n",
    "        env.debug = true;\n",
    "        env.logLevel = 'verbose';\n",
    "        const float32Data = new Float32Array(211*224*224).fill(1);\n",
    "        const inputTensor = new Tensor(\"float32\", float32Data, [211,224,224,1]);\n",
    "        // inputTensor.reshape([211,224,224,1])\n",
    "        console.log(inputTensor.data)\n",
    "        // data = imageDataToTensor(nvimage.img, [211,224,224,1])\n",
    "        \n",
    "\n",
    "        var session = await InferenceSession.create('../public/model/model.onnx');\n",
    "        console.log(session.inputNames[0])\n",
    "\n",
    "        // prepare feeds. use model input names as keys.\n",
    "        var feeds = { input_1:inputTensor };\n",
    "\n",
    "\n",
    "        // feed inputs and run\n",
    "        var results = await session.run(feeds, ['conv2d_transpose_4']);\n",
    "\n",
    "        // read from results\n",
    "        const dataC = results;\n",
    "        console.log(`data of result tensor 'c': ${dataC}`);\n",
    "\n",
    "        return dataC\n",
    "\n",
    "    } catch (e) {\n",
    "        console.error(`failed to inference ONNX model: ${e}.`);\n",
    "    }\n",
    "}\n",
    "\n",
    "var res = await main();\n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Float32Array(10587136) [\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "  1, 1, 1, 1,\n",
      "  ... 10587036 more items\n",
      "]\n",
      "input_1\n",
      "data of result tensor 'c': [object Object]\n",
      "{\n",
      "  conv2d_transpose_4: l {\n",
      "    dims: [ 211, 224, 224, 1 ],\n",
      "    type: 'float32',\n",
      "    data: Float32Array(10587136) [\n",
      "      0.002875823061913252,\n",
      "      -0.0035482447128742933,\n",
      "      0.0015134376008063555,\n",
      "      -0.00024906962062232196,\n",
      "      -0.0005567597690969706,\n",
      "      -0.0010869965190067887,\n",
      "      0.0001240931887878105,\n",
      "      0.00011437403009040281,\n",
      "      -0.00022227723093237728,\n",
      "      0.0006404236191883683,\n",
      "      0.00023755755682941526,\n",
      "      0.00027328336727805436,\n",
      "      0.0003408203483559191,\n",
      "      0.0003292314358986914,\n",
      "      -0.000867693976033479,\n",
      "      -0.000025216719222953543,\n",
      "      -0.00026807174435816705,\n",
      "      0.000623763888143003,\n",
      "      0.0004807364020962268,\n",
      "      0.00021195053705014288,\n",
      "      0.000463163509266451,\n",
      "      0.0006921188905835152,\n",
      "      -0.0005973390652798116,\n",
      "      -0.000010205082617176231,\n",
      "      -0.0005040581454522908,\n",
      "      0.0007603944977745414,\n",
      "      0.00030902118305675685,\n",
      "      0.0002571728837210685,\n",
      "      0.0002412117028143257,\n",
      "      0.0006016475963406265,\n",
      "      -0.0006641682703047991,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      0.0004117638454772532,\n",
      "      0.0006144867511466146,\n",
      "      -0.0006235971814021468,\n",
      "      -0.000012708710528386291,\n",
      "      -0.00023926781432237476,\n",
      "      0.0007482169312424958,\n",
      "      0.00014902283146511763,\n",
      "      0.0002887848822865635,\n",
      "      0.0001842194324126467,\n",
      "      0.0003481882740743458,\n",
      "      -0.0007447589887306094,\n",
      "      0.000041315735870739445,\n",
      "      -0.00006177217437652871,\n",
      "      0.0006873163511045277,\n",
      "      0.00043464923510327935,\n",
      "      0.0002117853582603857,\n",
      "      0.00045981729635968804,\n",
      "      0.0005580204888246953,\n",
      "      -0.0005699909524992108,\n",
      "      0.0000015971015727700433,\n",
      "      -0.00028677735826931894,\n",
      "      0.000701667508110404,\n",
      "      0.0002965375024359673,\n",
      "      0.0002098641562042758,\n",
      "      0.0002538953849580139,\n",
      "      0.0005345850950106978,\n",
      "      -0.0007433714345097542,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      0.0004117638454772532,\n",
      "      0.0006144867511466146,\n",
      "      -0.0006235971814021468,\n",
      "      -0.000012708710528386291,\n",
      "      -0.00023926781432237476,\n",
      "      0.0007482169312424958,\n",
      "      0.00014902283146511763,\n",
      "      0.0002887848822865635,\n",
      "      0.0001842194324126467,\n",
      "      0.0003481882740743458,\n",
      "      -0.0007447589887306094,\n",
      "      0.000041315735870739445,\n",
      "      -0.00006177217437652871,\n",
      "      0.0006873163511045277,\n",
      "      0.00043464923510327935,\n",
      "      0.0002117853582603857,\n",
      "      0.00045981729635968804,\n",
      "      0.0005580204888246953,\n",
      "      -0.0005699909524992108,\n",
      "      0.0000015971015727700433,\n",
      "      -0.00028677735826931894,\n",
      "      0.000701667508110404,\n",
      "      0.0002965375024359673,\n",
      "      0.0002098641562042758,\n",
      "      0.0002538953849580139,\n",
      "      0.0005345850950106978,\n",
      "      -0.0007433714345097542,\n",
      "      -0.000012408823749865405,\n",
      "      -0.00030952910310588777,\n",
      "      0.0006734536727890372,\n",
      "      0.00032858422491699457,\n",
      "      0.0002214566629845649,\n",
      "      ... 10587036 more items\n",
      "    ],\n",
      "    size: 10587136\n",
      "  }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import {InferenceSession, Tensor} from 'onnxruntime-node';\n",
    "const fs = require('fs')\n",
    "\n",
    "\n",
    "// use an async context to call onnxruntime functions.\n",
    "async function main() {\n",
    "    try {\n",
    "\n",
    "        // const float32Data = new Float32Array(160*256*256*1).fill(1);\n",
    "        // const inputTensor = new Tensor(\"float32\", float32Data, [160,256,256,1]);\n",
    "        const float32Data = new Float32Array(211*224*224).fill(1);\n",
    "        const inputTensor = new Tensor(\"float32\", float32Data, [211,224,224,1]);\n",
    "        // inputTensor.reshape([211,224,224,1])\n",
    "        console.log(inputTensor.data)\n",
    "        // data = imageDataToTensor(nvimage.img, [211,224,224,1])\n",
    "        \n",
    "\n",
    "        var session = await InferenceSession.create('../public/model/model.onnx');\n",
    "        console.log(session.inputNames[0])\n",
    "\n",
    "        // prepare feeds. use model input names as keys.\n",
    "        var feeds = { input_1:inputTensor };\n",
    "\n",
    "\n",
    "        // feed inputs and run\n",
    "        var results = await session.run(feeds, ['conv2d_transpose_4']);\n",
    "\n",
    "        // read from results\n",
    "        const dataC = results;\n",
    "        console.log(`data of result tensor 'c': ${dataC}`);\n",
    "\n",
    "        return dataC\n",
    "\n",
    "    } catch (e) {\n",
    "        console.error(`failed to inference ONNX model: ${e}.`);\n",
    "    }\n",
    "}\n",
    "\n",
    "var res = await main();\n",
    "console.log(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "function imageDataToTensor(data, dims){\n",
    "  // 1a. Extract the R, G, and B channels from the data to form a 3D int array\n",
    "  const [R, G, B] = new Array([], [], []);\n",
    "  for (let i = 0; i < data.length; i += 4) {\n",
    "    R.push(data[i]);\n",
    "    G.push(data[i + 1]);\n",
    "    B.push(data[i + 2]);\n",
    "    // 2. skip data[i + 3] thus filtering out the alpha channel\n",
    "  }\n",
    "  ///console.log(R);\n",
    "  //console.log(G);\n",
    "  //console.log(B);\n",
    "  // 1b. concatenate RGB ~= transpose [224, 224, 3] -> [3, 224, 224]\n",
    "  const transposedData = R.concat(G).concat(B);\n",
    "\n",
    "  // 3. convert to float32\n",
    "  let i, l = transposedData.length; // length, we need this for the loop\n",
    "  const float32Data = new Float32Array(dims[0]*dims[1]*dims[2]); // create the Float32Array for output\n",
    "  for (i = 0; i < l; i++) {\n",
    "    float32Data[i] = transposedData[i] / 255.0; // convert to float\n",
    "  }\n",
    "\n",
    "  const inputTensor = new Tensor(\"float32\", float32Data, dims);\n",
    "  return inputTensor;\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4:13 - Property 'splice' does not exist on type 'Float32Array'. Did you mean 'slice'?\n"
     ]
    }
   ],
   "source": [
    "let float32Data = new Float32Array(160*256*256*1).fill(0);\n",
    "console.log(float32Data.length)\n",
    "const newArray = Array.from({...float32Data, length:10587136}).fill(2)\n",
    "float32Data.splice(0, newArray.length, ...newArray);\n",
    "// console.log(float32Data.length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 10, 20, 30, 4, 5 ]\n"
     ]
    }
   ],
   "source": [
    "let a = [1,  2,  3,  4,  5]\n",
    "let b = [10, 20, 30]\n",
    "\n",
    "a.splice(0, b.length, ...b)\n",
    "\n",
    "console.log(a) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "TypeError: Only absolute URLs are supported\n",
      "    at getNodeRequestOptions (/home/thuy/repo/deepsyence/node_modules/node-fetch/lib/index.js:1305:9)\n",
      "    at /home/thuy/repo/deepsyence/node_modules/node-fetch/lib/index.js:1410:19\n",
      "    at new Promise (<anonymous>)\n",
      "    at fetch (/home/thuy/repo/deepsyence/node_modules/node-fetch/lib/index.js:1407:9)\n",
      "    at Object.createSessionHandler (/home/thuy/repo/deepsyence/node_modules/onnxruntime-web/dist/ort-web.node.js:6:159912)\n",
      "    at Function.create (/home/thuy/repo/deepsyence/node_modules/onnxruntime-common/dist/ort-common.node.js:6:6607)\n",
      "    at async evalmachine.<anonymous>:5:17\n",
      "    at async Object.execute (/home/thuy/.nvm/versions/node/v14.4.0/lib/node_modules/tslab/dist/executor.js:175:17)\n",
      "    at async JupyterHandlerImpl.handleExecuteImpl (/home/thuy/.nvm/versions/node/v14.4.0/lib/node_modules/tslab/dist/jupyter.js:219:18)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "async function runModel(model, preprocessedData) {\n",
    "  const start = new Date();\n",
    "  try {\n",
    "    const input = preprocessedData;\n",
    "    const feeds = {float_input: input};\n",
    "    // feeds[model.inputNames[0]] = preprocessedData;\n",
    "    const outputData = await model.run(feeds);\n",
    "    const end = new Date();\n",
    "    const inferenceTime = (end.getTime() - start.getTime());\n",
    "    const output = outputData[model.outputNames[0]];\n",
    "    return [output, inferenceTime];\n",
    "  } catch (e) {\n",
    "    console.error(e);\n",
    "    throw new Error();\n",
    "  }\n",
    "}\n",
    "\n",
    "//The softmax transforms values to be between 0 and 1\n",
    "function softmax(resultArray) {\n",
    "  // Get the largest value in the array.\n",
    "  const largestNumber = Math.max(...resultArray);\n",
    "  // Apply exponential function to each result item subtracted by the largest number, use reduce to get the previous result number and the current number to sum all the exponentials results.\n",
    "  const sumOfExp = resultArray.map((resultItem) => Math.exp(resultItem - largestNumber)).reduce((prevNumber, currentNumber) => prevNumber + currentNumber);\n",
    "  //Normalizes the resultArray by dividing by the sum of all exponentials; this normalization ensures that the sum of the components of the output vector is 1.\n",
    "  return resultArray.map((resultValue, index) => {\n",
    "    return Math.exp(resultValue - largestNumber) / sumOfExp;\n",
    "  });\n",
    "}\n",
    "\n",
    "const [res, time] =  await runModel(session, data);\n",
    "var output = res.data;\n",
    "var inferenceTime = time;\n",
    "var results = softmax(Array.prototype.slice.call(output))\n",
    "\n",
    "// var topResults = [];\n",
    "// for (let i = 0; i < results.length; i++) {\n",
    "//   if (results[i] > 0.3) {\n",
    "//     topResults.push([classes[i] + \": \" + results[i]]);\n",
    "//   }\n",
    "// }\n",
    "\n",
    "console.log(inferenceTime);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "async function runModel(model, preprocessedData) {\n",
    "    const start = new Date();\n",
    "    try {\n",
    "      const input = new ort.Tensor(new Float32Array(preprocessedData), [1, 380]);\n",
    "      const feeds = {float_input: input};\n",
    "      // feeds[model.inputNames[0]] = preprocessedData;\n",
    "      const outputData = await model.run(feeds);\n",
    "      const end = new Date();\n",
    "      const inferenceTime = (end.getTime() - start.getTime());\n",
    "      const output = outputData[model.outputNames[0]];\n",
    "      return [output, inferenceTime];\n",
    "    } catch (e) {\n",
    "      console.error(e);\n",
    "      throw new Error();\n",
    "    }\n",
    "  }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "//The softmax transforms values to be between 0 and 1\n",
    "function softmax(resultArray) {\n",
    "  // Get the largest value in the array.\n",
    "  const largestNumber = Math.max(...resultArray);\n",
    "  // Apply exponential function to each result item subtracted by the largest number, use reduce to get the previous result number and the current number to sum all the exponentials results.\n",
    "  const sumOfExp = resultArray.map((resultItem) => Math.exp(resultItem - largestNumber)).reduce((prevNumber, currentNumber) => prevNumber + currentNumber);\n",
    "  //Normalizes the resultArray by dividing by the sum of all exponentials; this normalization ensures that the sum of the components of the output vector is 1.\n",
    "  return resultArray.map((resultValue, index) => {\n",
    "    return Math.exp(resultValue - largestNumber) / sumOfExp;\n",
    "  });\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1:28 - Cannot find name 'runModel'.\n",
      "1:37 - Cannot find name 'session'.\n",
      "4:15 - Cannot find name 'softmax'.\n"
     ]
    }
   ],
   "source": [
    "const [res, time] =  await runModel(session, data);\n",
    "var output = res.data;\n",
    "var inferenceTime = time;\n",
    "var results = softmax(Array.prototype.slice.call(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var topResults = [];\n",
    "for (let i = 0; i < results.length; i++) {\n",
    "  if (results[i] > 0.3) {\n",
    "    topResults.push([classes[i] + \": \" + results[i]]);\n",
    "  }\n",
    "}\n",
    "\n",
    "console.log(topResults);"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "6f7c4d44365b28014734406e4d617c1e1f76ea196def854c7b951a230f6e24f1"
  },
  "kernelspec": {
   "display_name": "JavaScript",
   "language": "javascript",
   "name": "jslab"
  },
  "language_info": {
   "file_extension": ".js",
   "mimetype": "text/javascript",
   "name": "javascript",
   "version": ""
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
